{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pygraphviz as pgv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from lentil import datatools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Grockit Kaggle Comp](https://www.kaggle.com/c/WhatDoYouKnow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interaction_history_from_grockit_data_set(data):\n",
    "    \"\"\"\n",
    "    Parse Grockit data set into an interaction history\n",
    "    \n",
    "    :param pd.DataFrame data: A dataframe of raw interactions\n",
    "    :rtype: datatools.InteractionHistory\n",
    "    :return: An interaction history object\n",
    "    \"\"\"\n",
    "    \n",
    "    data['round_started_at'] = pd.to_datetime(data['round_started_at'], format='%Y-%m-%d %H:%M:%S', coerce=True)\n",
    "    data['answered_at'] = pd.to_datetime(data['answered_at'], format='%Y-%m-%d %H:%M:%S', coerce=True)\n",
    "        \n",
    "    # sort by timestamp\n",
    "    data.sort('answered_at', inplace=True, axis=0)\n",
    "    \n",
    "    # compute response times\n",
    "    data['duration'] = (data['answered_at'] - data['round_started_at']) / np.timedelta64(1, 's')\n",
    "    \n",
    "    # get relevant columns and rename them\n",
    "    data = data[['user_id', 'correct', 'question_id', 'answered_at', 'duration']]\n",
    "    data.columns = ['student_id', 'outcome', 'module_id', 'timestamp', 'duration']\n",
    "    \n",
    "    # only keep interactions with binary outcomes and positive response times\n",
    "    data = data[((data['outcome']==1) | (data['outcome']==0)) & (data['duration'] > 0)]\n",
    "    \n",
    "    # cast outcomes from 0/1 to False/True\n",
    "    data['outcome'] = data['outcome'].apply(lambda x: x == 1)\n",
    "    \n",
    "    student_timesteps = defaultdict(int)\n",
    "    timesteps = [None] * len(data)\n",
    "    for i, (_, ixn) in enumerate(data.iterrows()):\n",
    "        student_timesteps[ixn['student_id']] += 1\n",
    "        timesteps[i] = student_timesteps[ixn['student_id']]\n",
    "    data['timestep'] = timesteps\n",
    "    \n",
    "    data['module_type'] = [datatools.AssessmentInteraction.MODULETYPE] * len(data)\n",
    "    \n",
    "    lesson_data = data.copy(deep=True)\n",
    "    lesson_data['module_type'] = [datatools.LessonInteraction.MODULETYPE] * len(lesson_data)\n",
    "    \n",
    "    return datatools.InteractionHistory(\n",
    "        pd.concat([data, lesson_data], axis=0),\n",
    "        sort_by_timestep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join('data', 'grockit', 'valid_training.csv')\n",
    "df = pd.read_csv(data_path, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print '\\n'.join(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Number of interactions = %d\" % len(df)\n",
    "print \"Number of unique students = %d\" % len(df['user_id'].unique())\n",
    "print \"Number of unique modules = %d\" % len(df['question_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Number of interactions per student')\n",
    "plt.ylabel('Frequency (number of students)')\n",
    "plt.hist(df['user_id'].value_counts().values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Number of interactions per problem')\n",
    "plt.ylabel('Frequency (number of problems)')\n",
    "plt.hist(df['question_id'].value_counts().values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unfiltered_history = interaction_history_from_grockit_data_set(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[KDD Cup 2010](https://pslcdatashop.web.cmu.edu/KDDCup/downloads.jsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interaction_history_from_kdd_cup_data_set(data):\n",
    "    \"\"\"\n",
    "    Parse a KDD Cup data set into an interaction history\n",
    "    \n",
    "    :param pd.DataFrame data: A dataframe of raw interactions\n",
    "    :rtype: datatools.InteractionHistory\n",
    "    :return: An interaction history object\n",
    "    \"\"\"\n",
    "    # sort by timestamp\n",
    "    data.sort('Step Start Time', inplace=True, axis=0)\n",
    "    \n",
    "    # get relevant columns and rename them\n",
    "    data = data[['Anon Student Id', 'Correct First Attempt', 'Problem Name', 'Step Duration (sec)']]\n",
    "    data.columns = ['student_id', 'outcome', 'module_id', 'duration']\n",
    "    \n",
    "    # only keep interactions with binary outcomes and positive response times\n",
    "    data = data[((data['outcome']==1) | (data['outcome']==0)) & (data['duration'] > 0)]\n",
    "    \n",
    "    # cast outcomes from 0/1 to False/True\n",
    "    data['outcome'] = data['outcome'].apply(lambda x: x == 1)\n",
    "    \n",
    "    student_timesteps = defaultdict(int)\n",
    "    timesteps = [None] * len(data)\n",
    "    for i, (_, ixn) in enumerate(data.iterrows()):\n",
    "        student_timesteps[ixn['student_id']] += 1\n",
    "        timesteps[i] = student_timesteps[ixn['student_id']]\n",
    "    data['timestep'] = timesteps\n",
    "    \n",
    "    data['module_type'] = [datatools.AssessmentInteraction.MODULETYPE] * len(data)\n",
    "    \n",
    "    lesson_data = data.copy(deep=True)\n",
    "    lesson_data['module_type'] = [datatools.LessonInteraction.MODULETYPE] * len(lesson_data)\n",
    "    \n",
    "    return datatools.InteractionHistory(\n",
    "        pd.concat([data, lesson_data], axis=0),\n",
    "        sort_by_timestep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join('data',\n",
    "                         'bridge_to_algebra_2006_2007',\n",
    "                         'bridge_to_algebra_2006_2007_train.txt')\n",
    "df = pd.read_csv(data_path, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print '\\n'.join(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Number of interactions = %d\" % len(df)\n",
    "print \"Number of unique students = %d\" % len(df['Anon Student Id'].unique())\n",
    "print \"Number of unique modules = %d\" % len(df['Problem Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Number of interactions per student')\n",
    "plt.ylabel('Frequency (number of students)')\n",
    "plt.hist(df['Anon Student Id'].value_counts().values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Number of interactions per problem')\n",
    "plt.ylabel('Frequency (number of problems)')\n",
    "plt.hist(df['Problem Name'].value_counts().values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unfiltered_history = interaction_history_from_kdd_cup_data_set(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Assistments](https://sites.google.com/site/assistmentsdata/home/assistment-2009-2010-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interaction_history_from_assistments_data_set(\n",
    "    data,\n",
    "    duration_column='ms_first_response_time',\n",
    "    module_id_column='problem_id'):\n",
    "    \"\"\"\n",
    "    Parse dataframe of assistments interactions into an interaction history\n",
    "\n",
    "    :param pd.DataFrame assistments_data: A raw history from assistments\n",
    "    :param str duration_column: Column to use as interaction duration\n",
    "    :param str module_id_column: Column to use as module_id\n",
    "    :rtype: datatools.InteractionHistory\n",
    "    :return: An interaction history\n",
    "    \"\"\"\n",
    "    # sort by order_id\n",
    "    data.sort('order_id', inplace=True, axis=0)\n",
    "    \n",
    "    # get relevant columns and rename them\n",
    "    data = data[['user_id', 'correct', duration_column, module_id_column]]\n",
    "    data.columns = ['student_id', 'outcome', 'duration', 'module_id']\n",
    "\n",
    "    # only keep interactions with binary outcomes and positive response times\n",
    "    data = data[((data['outcome']==1) | (data['outcome']==0)) & (data['duration'] > 0)]\n",
    "    \n",
    "    # cast outcomes from int to bool\n",
    "    data['outcome'] = data['outcome'].apply(lambda x: x == 1)\n",
    "\n",
    "    # map response times from milliseconds to seconds\n",
    "    data['duration'] = data['duration'].apply(lambda x: x / 1000)\n",
    "\n",
    "    # existing interactions are all assessment interactions\n",
    "    data['module_type'] = [datatools.AssessmentInteraction.MODULETYPE] * len(data)\n",
    "\n",
    "    # add timesteps\n",
    "    timesteps = [None] * len(data)\n",
    "    student_timesteps = defaultdict(int)\n",
    "    for i, (_, ixn) in enumerate(data.iterrows()):\n",
    "        student_timesteps[ixn['student_id']] += 1\n",
    "        timesteps[i] = student_timesteps[ixn['student_id']]\n",
    "    data['timestep'] = timesteps\n",
    "\n",
    "    # add artificial lesson interactions\n",
    "    lesson_data = data.copy(deep=True)\n",
    "    lesson_data['module_type'] = [datatools.LessonInteraction.MODULETYPE] * len(data)\n",
    "\n",
    "    return datatools.InteractionHistory(\n",
    "        pd.concat([data, lesson_data]),\n",
    "        sort_by_timestep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join('data', 'assistments_2009_2010.csv')\n",
    "df = pd.read_csv(data_path, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print '\\n'.join(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Number of interactions = %d\" % (len(df))\n",
    "print \"Number of unique students = %d\" % (len(df['user_id'].unique()))\n",
    "print \"Number of unique modules = %d\" % (len(df['problem_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Number of interactions per student')\n",
    "plt.ylabel('Frequency (number of students)')\n",
    "plt.hist(df['user_id'].value_counts().values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Number of interactions per problem')\n",
    "plt.ylabel('Frequency (number of problems)')\n",
    "plt.hist(df['problem_id'].value_counts().values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unfiltered_history = interaction_history_from_assistments_data_set(\n",
    "    df,\n",
    "    module_id_column='problem_id',\n",
    "    duration_column='ms_first_response_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the interaction history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_history(history, min_num_ixns=5, max_num_ixns=sys.maxint):\n",
    "    \"\"\"\n",
    "    Filter history for students with histories of bounded length,\n",
    "    and modules with enough interactions\n",
    "    \n",
    "    :param datatools.InteractionHistory history: An interaction history\n",
    "    :param int min_num_ixns: Minimum number of timesteps in student history,\n",
    "        and minimum number of interactions for module\n",
    "    \n",
    "    :param int max_num_ixns: Maximum number of timesteps in student history\n",
    "    :rtype: datatools.InteractionHistory\n",
    "    :return: A filtered interaction history\n",
    "    \"\"\"\n",
    "    students = set(history.data['student_id'][(\n",
    "                history.data['timestep'] > min_num_ixns) & (\n",
    "                history.data['module_type']==datatools.AssessmentInteraction.MODULETYPE)])\n",
    "    students -= set(history.data['student_id'][history.data['timestep'] >= max_num_ixns])\n",
    "    \n",
    "    modules = {module_id for module_id, group in history.data.groupby('module_id') if len(group) > min_num_ixns}\n",
    "\n",
    "    return datatools.InteractionHistory(\n",
    "        history.data[(history.data['student_id'].isin(students)) & (\n",
    "                history.data['module_id'].isin(modules))],\n",
    "        reindex_timesteps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply the filter a couple of times, since removing student histories\n",
    "# may cause certain modules to drop below the min_num_ixns threshold,\n",
    "# and removing modules may cause student histories to drop below\n",
    "# the min_num_ixns threshold\n",
    "REPEATED_FILTER = 3 # number of times to repeat filtering\n",
    "history = reduce(\n",
    "    lambda acc, _: filter_history(acc, min_num_ixns=75, max_num_ixns=1000), \n",
    "    range(REPEATED_FILTER), unfiltered_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to pickled interaction history file\n",
    "history_path = os.path.join('data', 'grockit_history.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load history from file\n",
    "with open(history_path, 'rb') as f:\n",
    "    history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# serialize history\n",
    "with open(history_path, 'wb') as f:\n",
    "    pickle.dump(history, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore basic stats about interaction history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = history.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_interactions = len(df)\n",
    "value_counts = df['module_type'].value_counts()\n",
    "num_assessment_ixns = value_counts.get(datatools.AssessmentInteraction.MODULETYPE, 0)\n",
    "num_lesson_ixns = value_counts.get(datatools.LessonInteraction.MODULETYPE, 0)\n",
    "\n",
    "print \"Number of interactions = %d\" % (num_interactions)\n",
    "print \"Number of assessment interactions = %d\" % (num_assessment_ixns)\n",
    "print \"Number of lesson interactions = %d\" % (num_lesson_ixns)\n",
    "\n",
    "num_students = history.num_students()\n",
    "\n",
    "print \"Number of unique students: %d\" % (num_students)\n",
    "\n",
    "num_assessments = history.num_assessments()\n",
    "\n",
    "print \"Number of unique assessments: %d\" % (num_assessments)\n",
    "\n",
    "num_lessons = history.num_lessons()\n",
    "\n",
    "print \"Number of unique lessons: %d\" % (num_lessons)\n",
    "\n",
    "value_counts = df['outcome'].value_counts()\n",
    "num_passes = value_counts.get(True, 0)\n",
    "num_fails = value_counts.get(False, 0)\n",
    "pass_rate = num_passes / (num_passes + num_fails)\n",
    "\n",
    "print \"Overall pass rate: %f\" % (pass_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "for _, group in df.groupby('student_id'):\n",
    "    d.extend(group['timestep'].value_counts().values)\n",
    "d = np.array(d) - 1 # remove the lesson interaction at each timestep\n",
    "\n",
    "plt.xlabel('Number of assessment interactions per timestep')\n",
    "plt.ylabel('Frequency (number of timesteps)')\n",
    "plt.hist(d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timestamps = pd.DatetimeIndex(df['timestamp'])\n",
    "\n",
    "print \"Beginning of data set = %s\" % (min(timestamps))\n",
    "print \"End of data set = %s\" % (max(timestamps))\n",
    "\n",
    "hours = timestamps.hour\n",
    "plt.xlabel('Hour of interaction')\n",
    "plt.ylabel('Frequency (number of interactions)')\n",
    "plt.hist(hours, bins=24)\n",
    "plt.show()\n",
    "\n",
    "# Monday=0, Sunday=6\n",
    "days = timestamps.weekday\n",
    "plt.xlabel('Day of interaction')\n",
    "plt.ylabel('Frequency (number of interactions)')\n",
    "plt.hist(days, bins=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Frequency (number of interactions)')\n",
    "plt.hist(df['timestep'].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "durations = np.array([x for x in df['duration'].values])\n",
    "\n",
    "plt.xlabel('ln(response time, in seconds)')\n",
    "plt.ylabel('Frequency (number of interactions)')\n",
    "plt.hist(np.log(durations+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = df['student_id'].value_counts().values\n",
    "plt.xlabel('Number of interactions per student')\n",
    "plt.ylabel('Frequency (number of students)')\n",
    "plt.hist(counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = df['module_id'][df['module_type'] == datatools.LessonInteraction.MODULETYPE].value_counts().values\n",
    "\n",
    "plt.xlabel('Number of interactions per lesson module')\n",
    "plt.ylabel('Frequency (number of lesson modules)')\n",
    "plt.hist(counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = df['module_id'][df['module_type'] == datatools.AssessmentInteraction.MODULETYPE].value_counts().values\n",
    "\n",
    "plt.xlabel('Number of interactions per assessment module')\n",
    "plt.ylabel('Frequency (number of assessment modules)')\n",
    "plt.hist(counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = df.groupby(['student_id', 'module_id']).size().values\n",
    "\n",
    "plt.xlabel('Number of interactions per student per module')\n",
    "plt.ylabel('Frequency (number of student-module pairs)')\n",
    "plt.hist(counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_students_per_module = [len(group['student_id'].unique()) for _, group in df.groupby('module_id')]\n",
    "\n",
    "plt.xlabel('Number of students per module')\n",
    "plt.ylabel('Frequency (number of modules)')\n",
    "plt.hist(num_students_per_module)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped = df[df['module_type']==datatools.AssessmentInteraction.MODULETYPE].groupby('student_id')\n",
    "num_assessments_per_student = [len(group['module_id']) for _, group in grouped]\n",
    "\n",
    "plt.xlabel('Number of assessment modules per student')\n",
    "plt.ylabel('Frequency (number of students)')\n",
    "plt.hist(num_assessments_per_student)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = df[df['module_type']==datatools.LessonInteraction.MODULETYPE].groupby('student_id')\n",
    "num_lessons_per_student = [len(group['module_id']) for _, group in grouped]\n",
    "\n",
    "plt.xlabel('Number of lesson modules per student')\n",
    "plt.ylabel('Frequency (number of students)')\n",
    "plt.hist(num_lessons_per_student)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pass_rates(grouped):\n",
    "    \"\"\"\n",
    "    Get pass rate for each group\n",
    "    \n",
    "    :param pd.GroupBy grouped: A grouped dataframe\n",
    "    :rtype: dict[str, float]\n",
    "    :return: A dictionary mapping group name to pass rate\n",
    "    \"\"\"\n",
    "    pass_rates = {}\n",
    "    for name, group in grouped:\n",
    "        vc = group['outcome'].value_counts()\n",
    "        if True not in vc:\n",
    "            pass_rates[name] = 0\n",
    "        else:\n",
    "            pass_rates[name] = vc[True] / len(group)\n",
    "    return pass_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = df[df['module_type']==datatools.AssessmentInteraction.MODULETYPE].groupby('student_id')\n",
    "\n",
    "plt.xlabel('Student pass rate')\n",
    "plt.ylabel('Frequency (number of students)')\n",
    "plt.hist(get_pass_rates(grouped).values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = df[df['module_type']==datatools.AssessmentInteraction.MODULETYPE].groupby('module_id')\n",
    "\n",
    "plt.xlabel('Assessment pass rate')\n",
    "plt.ylabel('Frequency (number of assessments)')\n",
    "plt.hist(get_pass_rates(grouped).values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_flow_graph(interaction_logs):\n",
    "    \"\"\"\n",
    "    Create a graphviz object for the graph of \n",
    "    module transitions across all student paths\n",
    "    \n",
    "    :param pd.DataFrame interaction_logs: An interaction history\n",
    "    :rtype pgv.AGraph\n",
    "    :return Graph of module transitions in student paths\n",
    "    \"\"\"\n",
    "    G = pgv.AGraph(directed=True)\n",
    "\n",
    "    for module_id in interaction_logs['module_id'].unique():\n",
    "        G.add_node(module_id)\n",
    "\n",
    "    E = defaultdict(set)\n",
    "    grouped = interaction_logs.groupby('student_id')\n",
    "    for student_id, group in grouped:\n",
    "        module_ids_in_student_path = group['module_id']\n",
    "        for source_node, target_node in zip(module_ids_in_student_path[:-1], module_ids_in_student_path[1:]):\n",
    "            if source_node != target_node: # stationary\n",
    "                E[(source_node, target_node)] |= {student_id}\n",
    "\n",
    "    for (source_node, target_node), students_that_made_transition in E.iteritems():\n",
    "        G.add_edge(\n",
    "            source_node,\n",
    "            target_node,\n",
    "            weight=len(students_that_made_transition))\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = make_flow_graph(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flow_graph_path = os.path.join('data', 'grockit_flow_graph.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.write(flow_graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
