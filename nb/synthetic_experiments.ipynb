{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from lentil import datatools\n",
    "from lentil import datasynth\n",
    "from lentil import evaluate\n",
    "from lentil import models\n",
    "from lentil import est\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a synthetic 1PL/2PL IRT model and sample an interaction history from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_students = 2000\n",
    "num_assessments = 3000\n",
    "num_ixns_per_student = 1000\n",
    "\n",
    "USING_2PL = False # False => using 1PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proficiencies = np.random.normal(0, 1, num_students)\n",
    "difficulties = np.random.normal(0, 1, num_assessments)\n",
    "\n",
    "if USING_2PL:\n",
    "    discriminabilities = np.random.normal(0, 1, num_assessments)\n",
    "else:\n",
    "    discriminabilities = np.ones(num_assessments)\n",
    "\n",
    "student_ids = ['S'+str(x) for x in xrange(num_students)]\n",
    "assessment_ids = ['A'+str(x) for x in xrange(num_assessments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ixns = [None] * (num_students * num_ixns_per_student)\n",
    "assessment_idxes = range(num_assessments)\n",
    "for student_idx, student_id in enumerate(student_ids):\n",
    "    for t in xrange(num_ixns_per_student):\n",
    "        module_idx = random.choice(assessment_idxes)\n",
    "        pass_likelihood = 1 / (1 + math.exp(-(discriminabilities[module_idx]*proficiencies[student_idx] + difficulties[module_idx])))\n",
    "        ixns[student_idx * num_ixns_per_student + t] = {\n",
    "            'student_id' : student_id, \n",
    "            'module_id' : assessment_ids[module_idx], \n",
    "            'module_type' : datatools.AssessmentInteraction.MODULETYPE,\n",
    "            'outcome' : np.random.random() < pass_likelihood, \n",
    "            'timestep' : t+1\n",
    "        }\n",
    "history = datatools.InteractionHistory(pd.DataFrame(ixns))\n",
    "history.idx_of_student_id = lambda x: int(x[1:])\n",
    "history.idx_of_assessment_id = lambda x: int(x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mirt_model = models.MIRTModel(history, dims=1, using_assessment_factors=USING_2PL)\n",
    "estimator = est.MIRTMAPEstimator(\n",
    "    regularization_constant=1e-3,\n",
    "    ftol=1e-5,\n",
    "    debug_mode_on=True)\n",
    "mirt_model.fit(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onepl_model = models.OneParameterLogisticModel(\n",
    "    history.data, select_regularization_constant=True)\n",
    "onepl_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twopl_model = models.TwoParameterLogisticModel(\n",
    "    history.data, select_regularization_constant=True)\n",
    "twopl_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student_idxes = [int(k[1:]) for k in history.data['student_id'].unique()]\n",
    "assessment_idxes = [int(k[1:]) for k in history.data['module_id'].unique()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that `models.OneParameterLogisticModel` can recover parameters. We would only expect this to be possible when `USING_2PL = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('True difficulties')\n",
    "plt.ylabel('Estimated difficulties')\n",
    "plt.scatter(difficulties[assessment_idxes], onepl_model.model.coef_[0, num_students:])\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('Estimated difficulty - true difficulty')\n",
    "plt.ylabel('Frequency (number of assessments)')\n",
    "plt.hist(onepl_model.model.coef_[0, num_students:] - difficulties[assessment_idxes], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('True proficiencies')\n",
    "plt.ylabel('Estimated proficiencies')\n",
    "plt.scatter(proficiencies[student_idxes], onepl_model.model.coef_[0, :num_students])\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('Estimated proficiency - true proficiency')\n",
    "plt.ylabel('Frequency (number of students)')\n",
    "plt.hist(onepl_model.model.coef_[0, :num_students] - proficiencies[student_idxes], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that `models.TwoParameterLogisticModel` can recover parameters. We would only expect this to be possible when `USING_2PL = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('True difficulties')\n",
    "plt.ylabel('Estimated difficulties')\n",
    "plt.scatter(difficulties[assessment_idxes], twopl_model.model.coef_[0, (num_students*num_assessments):])\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('Estimated difficulty - true difficulty')\n",
    "plt.ylabel('Frequency (number of assessments)')\n",
    "plt.hist(twopl_model.model.coef_[0, (num_students*num_assessments):] - difficulties[assessment_idxes], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "est_params = twopl_model.model.coef_[0, :(num_students*num_assessments)]\n",
    "true_params = discriminabilities[:, None].dot(proficiencies[:, None].T).ravel()\n",
    "\n",
    "plt.xlabel('True proficiency*discriminability')\n",
    "plt.ylabel('Estimated proficiency*discriminability')\n",
    "plt.scatter(true_params, est_params)\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('Estimated proficiency*discriminability - true proficiency*discriminability')\n",
    "plt.ylabel('Frequency (number of student-assessment pairs)')\n",
    "plt.hist(est_params - true_params, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that `models.MIRTModel` can recover parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('True difficulties')\n",
    "plt.ylabel('Estimated difficulties')\n",
    "plt.scatter(difficulties, mirt_model.assessment_offsets)\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('Estimated difficulty - true difficulty')\n",
    "plt.ylabel('Frequency (number of assessments)')\n",
    "plt.hist(mirt_model.assessment_offsets - difficulties, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('True proficiencies')\n",
    "plt.ylabel('Estimated proficiencies')\n",
    "plt.scatter(proficiencies, mirt_model.student_factors[:, 0])\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('Estimated proficiency - true proficiency')\n",
    "plt.ylabel('Frequency (number of students)')\n",
    "plt.hist(mirt_model.student_factors[:, 0] - proficiencies, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('True discriminabilities')\n",
    "plt.ylabel('Estimated discriminabilities')\n",
    "plt.scatter(discriminabilities, mirt_model.assessment_factors[:, 0])\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('Estimated discriminability - true discriminability')\n",
    "plt.ylabel('Frequency (number of assessments)')\n",
    "plt.hist(mirt_model.assessment_factors[:, 0] - discriminabilities, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that all models achieve similar training AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# models.OneParameterLogisticModel\n",
    "evaluate.training_auc(onepl_model, history, plot_roc_curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# models.TwoParameterLogisticModel\n",
    "evaluate.training_auc(twopl_model, history, plot_roc_curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# models.MIRTModel\n",
    "evaluate.training_auc(mirt_model, history, plot_roc_curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# true model\n",
    "true_model = copy.deepcopy(mirt_model)\n",
    "true_model.student_factors[:, 0] = proficiencies\n",
    "true_model.assessment_factors[:, 0] = discriminabilities\n",
    "true_model.assessment_offsets = difficulties\n",
    "evaluate.training_auc(true_model, history, plot_roc_curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
