{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from lentil import datatools\n",
    "from lentil import datasynth\n",
    "from lentil import evaluate\n",
    "from lentil import models\n",
    "from lentil import est\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a synthetic 1PL/2PL IRT model and sample an interaction history from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_students = 2000\n",
    "num_assessments = 3000\n",
    "num_ixns_per_student = 1000\n",
    "\n",
    "USING_2PL = False # False => using 1PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proficiencies = np.random.normal(0, 1, num_students)\n",
    "difficulties = np.random.normal(0, 1, num_assessments)\n",
    "\n",
    "if USING_2PL:\n",
    "    discriminabilities = np.random.normal(0, 1, num_assessments)\n",
    "else:\n",
    "    discriminabilities = np.ones(num_assessments)\n",
    "\n",
    "student_ids = ['S'+str(x) for x in xrange(num_students)]\n",
    "assessment_ids = ['A'+str(x) for x in xrange(num_assessments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ixns = [None] * (num_students * num_ixns_per_student)\n",
    "assessment_idxes = range(num_assessments)\n",
    "for student_idx, student_id in enumerate(student_ids):\n",
    "    for t in xrange(num_ixns_per_student):\n",
    "        module_idx = random.choice(assessment_idxes)\n",
    "        pass_likelihood = 1 / (1 + math.exp(-(discriminabilities[module_idx]*proficiencies[student_idx] + difficulties[module_idx])))\n",
    "        ixns[student_idx * num_ixns_per_student + t] = {\n",
    "            'student_id' : student_id, \n",
    "            'module_id' : assessment_ids[module_idx], \n",
    "            'module_type' : datatools.AssessmentInteraction.MODULETYPE,\n",
    "            'outcome' : np.random.random() < pass_likelihood, \n",
    "            'timestep' : t+1\n",
    "        }\n",
    "history = datatools.InteractionHistory(pd.DataFrame(ixns))\n",
    "history.idx_of_student_id = lambda x: int(x[1:])\n",
    "history.idx_of_assessment_id = lambda x: int(x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mirt_model = models.MIRTModel(history, dims=1, using_assessment_factors=USING_2PL)\n",
    "estimator = est.MIRTMAPEstimator(\n",
    "    regularization_constant=1e-3,\n",
    "    ftol=1e-5,\n",
    "    debug_mode_on=True)\n",
    "mirt_model.fit(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onepl_model = models.OneParameterLogisticModel(\n",
    "    history.data, select_regularization_constant=True)\n",
    "onepl_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twopl_model = models.TwoParameterLogisticModel(\n",
    "    history.data, select_regularization_constant=True)\n",
    "twopl_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student_idxes = [int(k[1:]) for k in history.data['student_id'].unique()]\n",
    "assessment_idxes = [int(k[1:]) for k in history.data['module_id'].unique()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that `models.OneParameterLogisticModel` can recover parameters. We would only expect this to be possible when `USING_2PL = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('True difficulties')\n",
    "plt.ylabel('Estimated difficulties')\n",
    "plt.scatter(difficulties[assessment_idxes], onepl_model.model.coef_[0, num_students:])\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('Estimated difficulty - true difficulty')\n",
    "plt.ylabel('Frequency (number of assessments)')\n",
    "plt.hist(onepl_model.model.coef_[0, num_students:] - difficulties[assessment_idxes], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('True proficiencies')\n",
    "plt.ylabel('Estimated proficiencies')\n",
    "plt.scatter(proficiencies[student_idxes], onepl_model.model.coef_[0, :num_students])\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('Estimated proficiency - true proficiency')\n",
    "plt.ylabel('Frequency (number of students)')\n",
    "plt.hist(onepl_model.model.coef_[0, :num_students] - proficiencies[student_idxes], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that `models.TwoParameterLogisticModel` can recover parameters. We would only expect this to be possible when `USING_2PL = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('True difficulties')\n",
    "plt.ylabel('Estimated difficulties')\n",
    "plt.scatter(difficulties[assessment_idxes], twopl_model.model.coef_[0, (num_students*num_assessments):])\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('Estimated difficulty - true difficulty')\n",
    "plt.ylabel('Frequency (number of assessments)')\n",
    "plt.hist(twopl_model.model.coef_[0, (num_students*num_assessments):] - difficulties[assessment_idxes], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "est_params = twopl_model.model.coef_[0, :(num_students*num_assessments)]\n",
    "true_params = discriminabilities[:, None].dot(proficiencies[:, None].T).ravel()\n",
    "\n",
    "plt.xlabel('True proficiency*discriminability')\n",
    "plt.ylabel('Estimated proficiency*discriminability')\n",
    "plt.scatter(true_params, est_params)\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('Estimated proficiency*discriminability - true proficiency*discriminability')\n",
    "plt.ylabel('Frequency (number of student-assessment pairs)')\n",
    "plt.hist(est_params - true_params, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that `models.MIRTModel` can recover parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('True difficulties')\n",
    "plt.ylabel('Estimated difficulties')\n",
    "plt.scatter(difficulties, mirt_model.assessment_offsets)\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('Estimated difficulty - true difficulty')\n",
    "plt.ylabel('Frequency (number of assessments)')\n",
    "plt.hist(mirt_model.assessment_offsets - difficulties, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('True proficiencies')\n",
    "plt.ylabel('Estimated proficiencies')\n",
    "plt.scatter(proficiencies, mirt_model.student_factors[:, 0])\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('Estimated proficiency - true proficiency')\n",
    "plt.ylabel('Frequency (number of students)')\n",
    "plt.hist(mirt_model.student_factors[:, 0] - proficiencies, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('True discriminabilities')\n",
    "plt.ylabel('Estimated discriminabilities')\n",
    "plt.scatter(discriminabilities, mirt_model.assessment_factors[:, 0])\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('Estimated discriminability - true discriminability')\n",
    "plt.ylabel('Frequency (number of assessments)')\n",
    "plt.hist(mirt_model.assessment_factors[:, 0] - discriminabilities, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that all models achieve similar training AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# models.OneParameterLogisticModel\n",
    "evaluate.training_auc(onepl_model, history, plot_roc_curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# models.TwoParameterLogisticModel\n",
    "evaluate.training_auc(twopl_model, history, plot_roc_curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# models.MIRTModel\n",
    "evaluate.training_auc(mirt_model, history, plot_roc_curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# true model\n",
    "true_model = copy.deepcopy(mirt_model)\n",
    "true_model.student_factors[:, 0] = proficiencies\n",
    "true_model.assessment_factors[:, 0] = discriminabilities\n",
    "true_model.assessment_offsets = difficulties\n",
    "evaluate.training_auc(true_model, history, plot_roc_curve=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a synthetic embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_students = 10000\n",
    "num_assessment_interactions_per_step = 100\n",
    "grid_size = 5\n",
    "embedding_dimension = 2\n",
    "\n",
    "num_assessments = grid_size ** 2\n",
    "num_lessons = 2 * grid_size * (grid_size - 1)\n",
    "num_lesson_interactions_per_student = 2 * (grid_size - 1) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S = np.zeros((num_students, embedding_dimension, num_lesson_interactions_per_student))\n",
    "A = np.zeros((num_assessments, embedding_dimension))\n",
    "L = np.zeros((num_lessons, embedding_dimension))\n",
    "Q = np.zeros((num_lessons, embedding_dimension))\n",
    "\n",
    "lesson_idx_of_loc = {}\n",
    "assessment_idx_of_loc = {}\n",
    "\n",
    "cell_size = 10 / (grid_size - 1)\n",
    "lesson_count = 0\n",
    "for i in xrange(grid_size):\n",
    "    for j in xrange(grid_size):\n",
    "        A[grid_size * i + j, :] = [i, j]\n",
    "        assessment_idx_of_loc[(i, j)] = grid_size * i + j\n",
    "        \n",
    "        if j < grid_size - 1:\n",
    "            Q[lesson_count, :] = [i, j]\n",
    "            L[lesson_count, :] = [0, 1]\n",
    "            lesson_idx_of_loc[(i, j, 0, 1)] = lesson_count\n",
    "            lesson_count += 1\n",
    "        \n",
    "        if i < grid_size - 1:\n",
    "            Q[lesson_count, :] = [i, j]\n",
    "            L[lesson_count, :] = [1, 0]\n",
    "            lesson_idx_of_loc[(i, j, 1, 0)] = lesson_count\n",
    "            lesson_count += 1\n",
    "            \n",
    "A *= cell_size\n",
    "Q *= cell_size\n",
    "L *= cell_size\n",
    "\n",
    "A = np.maximum(1e-3, A)\n",
    "Q = np.maximum(1e-3, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample interactions from the synthetic embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_of_loc = lambda x: '-'.join(str(z) for z in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for student_idx in xrange(num_students):\n",
    "    student_id = 'S' + str(student_idx)\n",
    "    steps = ([(0, 1)] * (grid_size - 1)) +  ([(1, 0)] * (grid_size - 1))\n",
    "    random.shuffle(steps)\n",
    "    \n",
    "    x, y = 0, 0\n",
    "    t = 1\n",
    "    assessment_idx = assessment_idx_of_loc[(0, 0)]\n",
    "    assessment_id = id_of_loc(assessment_loc_of_idx[assessment_idx])\n",
    "    pass_likelihood = 1 / (1 + math.exp(-(np.dot(S[student_idx, :, t], A[assessment_idx, :]) / np.linalg.norm(A[assessment_idx, :]) - np.linalg.norm(A[assessment_idx, :]))))\n",
    "    outcome = random.random() < pass_likelihood\n",
    "    data.append({\n",
    "        'student_id' : student_id, \n",
    "        'module_id' : assessment_id,\n",
    "        'module_type' : datatools.AssessmentInteraction.MODULETYPE,\n",
    "        'timestep' : t,\n",
    "        'outcome' : outcome})\n",
    "    \n",
    "    for i, j in steps:\n",
    "        lesson_idx = lesson_idx_of_loc[(x, y, i, j)]\n",
    "        lesson_id = id_of_loc(lesson_loc_of_idx[lesson_idx])\n",
    "        data.append({\n",
    "            'student_id' : student_id,\n",
    "            'module_id' : lesson_id,\n",
    "            'module_type' : datatools.LessonInteraction.MODULETYPE,\n",
    "            'timestep' : t, \n",
    "            'outcome' : None})\n",
    "        \n",
    "        x += i\n",
    "        y += j\n",
    "        # DEBUG\n",
    "        S[student_idx, :, t+1] = S[student_idx, :, t] + L[lesson_idx, :]# / (1 + math.exp(-(np.dot(S[student_idx, :, t], Q[lesson_idx, :]) / np.linalg.norm(Q[lesson_idx, :]) - np.linalg.norm(Q[lesson_idx, :]))))\n",
    "        \n",
    "        t += 1\n",
    "        for _ in xrange(num_assessment_interactions_per_step):\n",
    "            assessment_idx = random.randint(0, num_assessments - 1)\n",
    "            assessment_id = id_of_loc(assessment_loc_of_idx[assessment_idx])\n",
    "            pass_likelihood = 1 / (1 + math.exp(-(np.dot(S[student_idx, :, t], A[assessment_idx, :]) / np.linalg.norm(A[assessment_idx, :]) - np.linalg.norm(A[assessment_idx, :]))))\n",
    "            outcome = random.random() < pass_likelihood\n",
    "            # BEGIN DEBUG\n",
    "            if assessment_idx_of_loc[(0, 0)] == assessment_idx:\n",
    "                outcome = random.random() < 0.1\n",
    "            # END DEBUG\n",
    "            data.append({\n",
    "                'student_id' : student_id,\n",
    "                'module_id' : assessment_id,\n",
    "                'module_type' : datatools.AssessmentInteraction.MODULETYPE,\n",
    "                'timestep' : t,\n",
    "                'outcome' : outcome})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history = datatools.InteractionHistory(pd.DataFrame(data))\n",
    "\n",
    "assessment_idx_map = {id_of_loc(loc): idx for idx, loc in assessment_loc_of_idx.iteritems()}\n",
    "lesson_idx_map = {id_of_loc(loc): idx for idx, loc in lesson_loc_of_idx.iteritems()}\n",
    "history.compute_idx_maps(assessment_idx=assessment_idx_map, lesson_idx=lesson_idx_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(history.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history_path = os.path.join('data', 'lse_synthetic_history.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(history_path, 'wb') as f:\n",
    "    pickle.dump(history, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate an embedding from the sampled interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.EmbeddingModel(\n",
    "    history, embedding_dimension=2, \n",
    "    using_lessons=True, using_prereqs=False, using_bias=True, \n",
    "    learning_update_variance_constant=0.5)\n",
    "\n",
    "estimator = est.EmbeddingMAPEstimator(\n",
    "    regularization_constant=1e-3, using_scipy=True, \n",
    "    debug_mode_on=True, ftol=1e-4)\n",
    "\n",
    "model.fit(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models.OneParameterLogisticModel(history.data, select_regularization_constant=True)\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate.training_auc(model, history, plot_roc_curve=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the estimated embedding vs. the true embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(A[:, 0], A[:, 1])\n",
    "for assessment_idx in xrange(num_assessments):\n",
    "    plt.annotate(id_of_assessment_idx(assessment_idx), (A[assessment_idx, 0], A[assessment_idx, 1]))\n",
    "\"\"\"\n",
    "for i in xrange(grid_size):\n",
    "    for j in xrange(grid_size):\n",
    "        if j < grid_size - 1:\n",
    "            assessment_idxes = [assessment_idx_of_loc[(i, j)], assessment_idx_of_loc[(i, j + 1)]]\n",
    "            plt.plot(A[assessment_idxes, 0], A[assessment_idxes, 1], c='black')\n",
    "            \n",
    "        if i < grid_size - 1:\n",
    "            assessment_idxes = [assessment_idx_of_loc[(i, j)], assessment_idx_of_loc[(i + 1, j)]]\n",
    "            plt.plot(A[assessment_idxes, 0], A[assessment_idxes, 1], c='black')\n",
    "\"\"\"\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(model.assessment_embeddings[:, 0], model.assessment_embeddings[:, 1])\n",
    "for assessment_idx in xrange(num_assessments):\n",
    "    plt.annotate(id_of_assessment_idx(assessment_idx), (model.assessment_embeddings[assessment_idx, 0], model.assessment_embeddings[assessment_idx, 1]))\n",
    "\"\"\"\n",
    "for i in xrange(grid_size):\n",
    "    for j in xrange(grid_size):\n",
    "        if j < grid_size - 1:\n",
    "            assessment_idxes = [assessment_idx_of_loc[(i, j)], assessment_idx_of_loc[(i, j + 1)]]\n",
    "            plt.plot(model.assessment_embeddings[assessment_idxes, 0], model.assessment_embeddings[assessment_idxes, 1], c='black')\n",
    "            \n",
    "        if i < grid_size - 1:\n",
    "            assessment_idxes = [assessment_idx_of_loc[(i, j)], assessment_idx_of_loc[(i + 1, j)]]\n",
    "            plt.plot(model.assessment_embeddings[assessment_idxes, 0], model.assessment_embeddings[assessment_idxes, 1], c='black')\n",
    "\"\"\"\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.quiver(Q[:, 0], Q[:, 1], L[:, 0], L[:, 1], pivot='tail', color='black')\n",
    "\"\"\"\n",
    "for i in xrange(grid_size):\n",
    "    for j in xrange(grid_size):\n",
    "        if j < grid_size - 1:\n",
    "            lesson_idxes = [lesson_idx_of_loc[(i, j)], lesson_idx_of_loc[(i, j + 1)]]\n",
    "            plt.plot(Q[lesson_idxes, 0], Q[lesson_idxes, 1], c='black')\n",
    "            \n",
    "        if i < grid_size - 1:\n",
    "            lesson_idxes = [lesson_idx_of_loc[(i, j)], lesson_idx_of_loc[(i + 1, j)]]\n",
    "            plt.plot(Q[lesson_idxes, 0], Q[lesson_idxes, 1], c='black')\n",
    "\"\"\"\n",
    "plt.xlabel('Skill 1')\n",
    "plt.ylabel('Skill 2')\n",
    "plt.xlim([-1, 11])\n",
    "plt.ylim([-1, 11])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.quiver(model.prereq_embeddings[:, 0], model.prereq_embeddings[:, 1], model.lesson_embeddings[:, 0], model.lesson_embeddings[:, 1], pivot='tail', color='black')\n",
    "\"\"\"\n",
    "for i in xrange(grid_size):\n",
    "    for j in xrange(grid_size):\n",
    "        if j < grid_size - 1:\n",
    "            lesson_idxes = [lesson_idx_of_loc[(i, j)], lesson_idx_of_loc[(i, j + 1)]]\n",
    "            plt.plot(model.prereq_embeddings[lesson_idxes, 0], model.prereq_embeddings[lesson_idxes, 1], c='black')\n",
    "            \n",
    "        if i < grid_size - 1:\n",
    "            lesson_idxes = [lesson_idx_of_loc[(i, j)], lesson_idx_of_loc[(i + 1, j)]]\n",
    "            plt.plot(model.prereq_embeddings[lesson_idxes, 0], model.prereq_embeddings[lesson_idxes, 1], c='black')\n",
    "\"\"\"\n",
    "plt.xlabel('Skill 1')\n",
    "plt.ylabel('Skill 2')\n",
    "plt.xlim([-1, 11])\n",
    "plt.ylim([-1, 11])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "right_lesson_idxes = [lesson_idx_of_loc[(i, j, 1, 0)] for i in xrange(grid_size) for j in xrange(grid_size) if (i, j, 1, 0) in lesson_idx_of_loc]\n",
    "up_lesson_idxes = [lesson_idx_of_loc[(i, j, 0, 1)] for i in xrange(grid_size) for j in xrange(grid_size) if (i, j, 0, 1) in lesson_idx_of_loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.quiver(0, 0, L[right_lesson_idxes, 0], L[right_lesson_idxes, 1], pivot='tail', color='red', alpha=0.25)\n",
    "plt.quiver(0, 0, L[up_lesson_idxes, 0], L[up_lesson_idxes, 1], pivot='tail', color='blue', alpha=0.25)\n",
    "\n",
    "plt.xlabel('Skill 1')\n",
    "plt.ylabel('Skill 2')\n",
    "plt.xlim([-1, 11])\n",
    "plt.ylim([-1, 11])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.quiver(0, 0, model.lesson_embeddings[right_lesson_idxes, 0], model.lesson_embeddings[right_lesson_idxes, 1], pivot='tail', color='red', alpha=0.25)\n",
    "plt.quiver(0, 0, model.lesson_embeddings[up_lesson_idxes, 0], model.lesson_embeddings[up_lesson_idxes, 1], pivot='tail', color='blue', alpha=0.25)\n",
    "\n",
    "plt.xlabel('Skill 1')\n",
    "plt.ylabel('Skill 2')\n",
    "plt.xlim([-1, 11])\n",
    "plt.ylim([-1, 11])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(L[right_lesson_idxes, 0], L[right_lesson_idxes, 1], color='red', label='1-0')\n",
    "plt.scatter(L[up_lesson_idxes, 0], L[up_lesson_idxes, 1], color='blue', label='0-1')\n",
    "plt.xlabel('Skill 1')\n",
    "plt.ylabel('Skill 2')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(model.lesson_embeddings[right_lesson_idxes, 0], model.lesson_embeddings[right_lesson_idxes, 1], color='red', label='1-0')\n",
    "plt.scatter(model.lesson_embeddings[up_lesson_idxes, 0], model.lesson_embeddings[up_lesson_idxes, 1], color='blue', label='0-1')\n",
    "plt.xlabel('Skill 1')\n",
    "plt.ylabel('Skill 2')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student_idxes = random.sample(range(num_students), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for student_idx in student_idxes:\n",
    "    plt.scatter(S[student_idx, 0, :], S[student_idx, 1, :], c='black')\n",
    "    for i in xrange(num_lesson_interactions_per_student):\n",
    "        plt.plot(S[student_idx, 0, i:(i+2)], S[student_idx, 1, i:(i+2)], c='black')\n",
    "    plt.xlabel('Skill 1')\n",
    "    plt.ylabel('Skill 2')\n",
    "    plt.title('student_id = %s' % history.id_of_student_idx(student_idx))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for student_idx in student_idxes:\n",
    "    plt.scatter(model.student_embeddings[student_idx, 0, :], model.student_embeddings[student_idx, 1, :], c='black')\n",
    "    for i in xrange(num_lesson_interactions_per_student):\n",
    "        plt.plot(model.student_embeddings[student_idx, 0, i:(i+2)], model.student_embeddings[student_idx, 1, i:(i+2)], c='black')\n",
    "    plt.xlabel('Skill 1')\n",
    "    plt.ylabel('Skill 2')\n",
    "    plt.title('student_id = %s' % history.id_of_student_idx(student_idx))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for student_idx in student_idxes:\n",
    "    for i in xrange(embedding_dimension):\n",
    "        plt.plot(S[student_idx, i, :], '-s', label='Skill 1')\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.ylabel('Skill')\n",
    "    plt.title('student_id = %s' % history.id_of_student_idx(student_idx))\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for student_idx in student_idxes:\n",
    "    for i in xrange(embedding_dimension):\n",
    "        plt.plot(model.student_embeddings[student_idx, i, :], '-s', label='Skill 1')\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.ylabel('Skill')\n",
    "    plt.title('student_id = %s' % history.id_of_student_idx(student_idx))\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
