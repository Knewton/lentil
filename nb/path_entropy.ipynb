{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from lentil import datatools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_path = os.path.join('data', 'grockit_history.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load history from file\n",
    "with open(history_path, 'rb') as f:\n",
    "    history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = history.data\n",
    "idx_of_module_id = {k: i for i, k in enumerate(df['module_id'].unique())}\n",
    "num_modules = len(idx_of_module_id)\n",
    "print \"Number of unique modules = %d\" % num_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute adjacency matrix of flow graph\n",
    "\n",
    "# sometimes a student history contains a module id\n",
    "# multiple times (for assessment and lesson interactions)\n",
    "IGNORE_REPEATED_MODULE_IDS = True\n",
    "\n",
    "X = np.zeros((num_modules, num_modules))\n",
    "grouped = df.groupby('student_id')['module_id']\n",
    "for student_id, group in grouped:\n",
    "    module_idxes = group.map(idx_of_module_id).values\n",
    "    \n",
    "    if IGNORE_REPEATED_MODULE_IDS:\n",
    "        filtered_module_idxes = []\n",
    "        module_idxes_seen = set()\n",
    "        for module_idx in module_idxes:\n",
    "            if module_idx in module_idxes_seen:\n",
    "                continue\n",
    "            filtered_module_idxes.append(module_idx)\n",
    "            module_idxes_seen |= {module_idx}\n",
    "    \n",
    "    # okay because module transitions are never repeated in this dataset\n",
    "    # if that's not true, then use np.add.at\n",
    "    # http://docs.scipy.org/doc/numpy/reference/generated/numpy.ufunc.at.html\n",
    "    X[module_idxes[:-1], module_idxes[1:]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# is the Markov chain ergodic?\n",
    "# i.e., is the flow graph strongly connected?\n",
    "G = nx.from_numpy_matrix(X, create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = nx.strongly_connected_components(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Sizes of strongly connected components:\"\n",
    "print [len(x) for x in sc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute transition probability matrix of Markov chain\n",
    "P = X / X.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# estimate stationary distribution of Markov chain\n",
    "stationary_distrn = np.diag(np.linalg.matrix_power(P, 2**15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev = P\n",
    "N = 15\n",
    "diffs = [None] * N\n",
    "for i in xrange(N):\n",
    "    nP = np.dot(prev, prev)\n",
    "    diffs[i] = np.linalg.norm(np.diag(nP) - np.diag(prev))\n",
    "    prev = nP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel('n')\n",
    "plt.ylabel('||diag(P^n)-diag(P^(n-1))||')\n",
    "plt.plot(2**np.arange(0, N, 1), diffs, '-s')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Entropy of Markov chain](http://math.ubbcluj.ro/~tradu/TI/coverch4_article.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entropy = -np.dot(stationary_distrn, np.nansum(P*np.log(P), axis=1))\n",
    "print \"Entropy = %f\" % entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = os.path.join('results', 'entropy', 'grockit_entropy.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(entropy, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare path entropy to gains from lesson prereq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sets = ['assistments_2009_2010', 'algebra_2006_2007', \n",
    "             'algebra_2005_2006', 'bridge_to_algebra_2006_2007', 'grockit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entropy_file_of_data_set = {k: os.path.join(\n",
    "        'results', 'entropy', '%s_entropy.pkl' % k) for k in data_sets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_file_of_data_set = {k: os.path.join(\n",
    "        'results', 'last', '%s_results_lesion.pkl' % k) for k in data_sets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entropies_of_models, results_of_models = [], []\n",
    "for ds in data_sets:\n",
    "    with open(entropy_file_of_data_set[ds], 'rb') as f:\n",
    "        entropies_of_models.append(pickle.load(f))\n",
    "    with open(results_file_of_data_set[ds], 'rb') as f:\n",
    "        results_of_models.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_plot(eps=1e-2):\n",
    "    gains_of_models = [compute_gain_from_prereq_model(results) for results in results_of_models]\n",
    "\n",
    "    plt.xlabel('Entropy of student paths')\n",
    "    plt.ylabel(name_of_gain_metric)\n",
    "    plt.scatter(entropies_of_models, gains_of_models)\n",
    "    for e, g, ds in zip(entropies_of_models, gains_of_models, data_sets):\n",
    "        plt.annotate(ds, (e+eps, g+eps))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_of_gain_metric = 'Relative AUC gain from prereq model'\n",
    "\n",
    "def compute_gain_from_prereq_model(res):\n",
    "    a = res.validation_auc_mean('d=2, without prereqs and bias')\n",
    "    b = res.validation_auc_mean('d=2, without prereqs, with bias')\n",
    "    c = res.validation_auc_mean('d=2, with prereqs, without bias')\n",
    "    d = res.validation_auc_mean('d=2, with prereqs and bias')\n",
    "    return np.mean([(c-a)/a, (d-b)/b])\n",
    "\n",
    "make_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_of_gain_metric = 'Relative AUC gain from prereq model (without bias)'\n",
    "\n",
    "def compute_gain_from_prereq_model(res):\n",
    "    a = res.validation_auc_mean('d=2, without prereqs and bias')\n",
    "    c = res.validation_auc_mean('d=2, with prereqs, without bias')\n",
    "    return (c-a)/a\n",
    "\n",
    "make_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_of_gain_metric = 'Relative AUC gain from prereq model (with bias)'\n",
    "\n",
    "def compute_gain_from_prereq_model(res):\n",
    "    b = res.validation_auc_mean('d=2, without prereqs, with bias')\n",
    "    d = res.validation_auc_mean('d=2, with prereqs and bias')\n",
    "    return (d-b)/b\n",
    "\n",
    "make_plot(eps=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_of_gain_metric = 'AUC gain from prereq model'\n",
    "\n",
    "def compute_gain_from_prereq_model(res):\n",
    "    a = res.validation_auc_mean('d=2, without prereqs and bias')\n",
    "    b = res.validation_auc_mean('d=2, without prereqs, with bias')\n",
    "    c = res.validation_auc_mean('d=2, with prereqs, without bias')\n",
    "    d = res.validation_auc_mean('d=2, with prereqs and bias')\n",
    "    return np.mean([c-a, d-b])\n",
    "\n",
    "make_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
