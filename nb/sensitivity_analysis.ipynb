{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from lentil import datatools\n",
    "from lentil import models\n",
    "from lentil import est\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_path = os.path.join('data', 'assistments_2009_2010.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(history_path, 'rb') as f:\n",
    "    history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_embedding(\n",
    "    embedding_kwargs,\n",
    "    estimator,\n",
    "    history,\n",
    "    filtered_history,\n",
    "    split_history=None):\n",
    "    \n",
    "    model = models.EmbeddingModel(history, **embedding_kwargs)\n",
    "    \n",
    "    estimator.filtered_history = filtered_history\n",
    "    if split_history is not None:\n",
    "        estimator.split_history = split_history\n",
    "    \n",
    "    model.fit(estimator)\n",
    "    \n",
    "    return model\n",
    "\n",
    "embedding_kwargs = {\n",
    "    'embedding_dimension' : 2,\n",
    "    'using_lessons' : True,\n",
    "    'using_prereqs' : True,\n",
    "    'using_bias' : True,\n",
    "    'learning_update_variance_constant' : 0.5\n",
    "}\n",
    "\n",
    "estimator = est.EmbeddingMAPEstimator(\n",
    "    regularization_constant=0.01,\n",
    "    using_scipy=True,\n",
    "    verify_gradient=False,\n",
    "    debug_mode_on=True,\n",
    "    ftol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_auc(y_trues, probas_preds, timesteps):\n",
    "    \"\"\"\n",
    "    Compute AUC across timesteps, given true labels and predicted likelihoods\n",
    "    \n",
    "    :param dict[str, list[list[int]]] y_trues: \n",
    "        A dictionary mapping student_id to a list \n",
    "        (indexed by timestep) of lists of true labels (-1/1 for fail/pass)\n",
    "        \n",
    "    :param dict[str, list[list[float]]] probas_preds:\n",
    "        A dictionary mapping student_id to a list\n",
    "        (indexed by timestep) of lists of pass likelihoods\n",
    "        \n",
    "    :param np.array timesteps: A list of timesteps\n",
    "    :rtype: list[float]\n",
    "    :return: A list of AUCs (one for each timestep)\n",
    "    \"\"\"\n",
    "    def get_auc(i):\n",
    "        y_trues_of_timestep = [o for student_id, y_trues_of_student in y_trues.iteritems() for o in y_trues_of_student[i]]\n",
    "        probas_preds_of_timestep = [p for student_id, y_trues_of_student in y_trues.iteritems() for p in probas_preds[student_id][i]]\n",
    "        if y_trues_of_timestep == probas_preds_of_timestep == []:\n",
    "            return None\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_trues_of_timestep, probas_preds_of_timestep)\n",
    "\n",
    "        return metrics.auc(fpr, tpr)\n",
    "    return [get_auc(i) for i in xrange(len(timesteps))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = history.data\n",
    "duration = history.duration()\n",
    "num_students = history.num_students()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 80-20 training-validation split\n",
    "num_left_out_students = int(0.2 * num_students)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does validation AUC vary with the length of student histories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_out_student_ids = {history.id_of_student_idx(\n",
    "        student_idx) for student_idx in random.sample(\n",
    "        range(num_students), num_left_out_students)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_trues_for_length_analysis = {k:[] for k in left_out_student_ids}\n",
    "probas_preds_for_length_analysis = {k:[] for k in left_out_student_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "START_LENGTH = 3\n",
    "END_LENGTH = duration\n",
    "NUM_LENGTHS = 25\n",
    "\n",
    "grouped = df.groupby('student_id')\n",
    "left_out_ixns = df['student_id'].isin(left_out_student_ids)\n",
    "left_in_ixns = ~left_out_ixns\n",
    "lengths = np.arange(START_LENGTH, END_LENGTH, (END_LENGTH - START_LENGTH) // NUM_LENGTHS)\n",
    "\n",
    "for i, t in enumerate(lengths):\n",
    "    print '%d of %d' % (i, len(lengths))\n",
    "    \n",
    "    filtered_history = df[(left_in_ixns) | (\n",
    "            (left_out_ixns) & (df['timestep']<=t))]\n",
    "    split_history = history.split_interactions_by_type(\n",
    "            filtered_history=filtered_history)\n",
    "    \n",
    "    model = build_embedding(\n",
    "        embedding_kwargs,\n",
    "        estimator,\n",
    "        history,\n",
    "        filtered_history,\n",
    "        split_history=split_history)\n",
    "    \n",
    "    for student_id in left_out_student_ids:\n",
    "        test_ixns = grouped.get_group(student_id)\n",
    "        test_ixns = test_ixns[(test_ixns['timestep']==t+1) & (\n",
    "                test_ixns['module_type']==datatools.AssessmentInteraction.MODULETYPE)]\n",
    "        if len(test_ixns)==0:\n",
    "            y_trues_for_length_analysis[student_id].append([])\n",
    "            probas_preds_for_length_analysis[student_id].append([])\n",
    "            continue\n",
    "        \n",
    "        y_trues_for_length_analysis[student_id].append(list(test_ixns['outcome'].apply(\n",
    "            lambda outcome: 1 if outcome else -1)))\n",
    "        probas_preds_for_length_analysis[student_id].append(list(test_ixns.apply(\n",
    "            model.assessment_pass_likelihood, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aucs = compute_auc(\n",
    "    y_trues_for_length_analysis, \n",
    "    probas_preds_for_length_analysis, \n",
    "    lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Sensitivity to length of student history')\n",
    "plt.xlabel('Length of student history (number of timesteps)')\n",
    "plt.ylabel('Area under ROC Curve')\n",
    "plt.plot(lengths, aucs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does validation AUC vary with the depth of student histories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we will train on interactions from t=T-depth to t=T\n",
    "# and validate on interactions at T=201 (more specifically, \n",
    "# the smallest T such that T>200 and the student has assessment interactions at T)\n",
    "T = 200\n",
    "students_with_long_histories = df[df['timestep'] > T]['student_id'].unique()\n",
    "left_out_student_ids = random.sample(\n",
    "    students_with_long_histories,\n",
    "    num_left_out_students) if num_left_out_students < len(students_with_long_histories) else students_with_long_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_trues_for_depth_analysis = {k:[] for k in left_out_student_ids}\n",
    "probas_preds_for_depth_analysis = {k:[] for k in left_out_student_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "truncations = {}\n",
    "grouped = df.groupby('student_id')\n",
    "for student_id in left_out_student_ids:\n",
    "        test_ixns = grouped.get_group(student_id)\n",
    "        test_ixns = test_ixns[(test_ixns['timestep']>=T+1) & (\n",
    "                test_ixns['module_type']==datatools.AssessmentInteraction.MODULETYPE)]\n",
    "        try:\n",
    "            truncations[student_id] = min(test_ixns['timestep'])-1\n",
    "        except ValueError:\n",
    "            left_out_student_ids.remove(student_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "START_DEPTH = 3\n",
    "END_DEPTH = T\n",
    "NUM_DEPTHS = 25\n",
    "\n",
    "left_out_ixns = df['student_id'].isin(left_out_student_ids)\n",
    "grouped = df.groupby('student_id')\n",
    "depths = np.arange(START_DEPTH, END_DEPTH, (END_DEPTH - START_DEPTH) // NUM_DEPTHS)\n",
    "\n",
    "for i, t in enumerate(depths):\n",
    "    print '%d of %d' % (i, len(depths))\n",
    "    \n",
    "    truncations_series = df['student_id'].map(truncations, na_action=None)\n",
    "    \n",
    "    filtered_history = df[(left_in_ixns) | (left_out_ixns & (\n",
    "                df['timestep']<=truncations_series) & (\n",
    "                df['timestep']>=truncations_series-t))]\n",
    "    split_history = history.split_interactions_by_type(\n",
    "            filtered_history=filtered_history)\n",
    "    \n",
    "    model = build_embedding(\n",
    "        embedding_kwargs,\n",
    "        estimator,\n",
    "        history,\n",
    "        filtered_history,\n",
    "        split_history=split_history)\n",
    "    \n",
    "    for student_id in left_out_student_ids:\n",
    "        test_ixns = grouped.get_group(student_id)\n",
    "        test_ixns = test_ixns[(\n",
    "                test_ixns['timestep']==truncations[student_id]+1) & (\n",
    "                test_ixns['module_type']==datatools.AssessmentInteraction.MODULETYPE)]\n",
    "        if len(test_ixns)==0:\n",
    "            y_trues_for_depth_analysis[student_id].append([])\n",
    "            probas_preds_for_depth_analysis[student_id].append([])\n",
    "            continue\n",
    "        \n",
    "        y_trues_for_depth_analysis[student_id].append(list(test_ixns['outcome'].apply(\n",
    "            lambda outcome: 1 if outcome else -1)))\n",
    "        probas_preds_for_depth_analysis[student_id].append(list(test_ixns.apply(\n",
    "            model.assessment_pass_likelihood, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aucs = compute_auc(\n",
    "    y_trues_for_depth_analysis, \n",
    "    probas_preds_for_depth_analysis, \n",
    "    depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Sensitivity to depth of student history')\n",
    "plt.xlabel('Depth of student history (number of lesson interactions)')\n",
    "plt.ylabel('Area under ROC Curve')\n",
    "plt.plot(depths, aucs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does validation AUC vary with the number of full student histories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_out_student_ids = {history.id_of_student_idx(\n",
    "        student_idx) for student_idx in random.sample(\n",
    "        range(num_students), num_left_out_students)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_trues_for_tset_size_analysis = {k:[] for k in left_out_student_ids}\n",
    "probas_preds_for_tset_size_analysis = {k:[] for k in left_out_student_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training set size = fraction of full student histories\n",
    "START_TRAINSET_SIZE = 0.1\n",
    "END_TRAINSET_SIZE = 1.0\n",
    "NUM_TRAINSET_SIZES = 25\n",
    "tset_sizes = np.arange(START_TRAINSET_SIZE, END_TRAINSET_SIZE, (END_TRAINSET_SIZE - START_TRAINSET_SIZE) / NUM_TRAINSET_SIZES)\n",
    "\n",
    "not_in_beginning = df['timestep'] > 2\n",
    "is_assessment_ixn = df['module_type'] == datatools.AssessmentInteraction.MODULETYPE\n",
    "left_out = df['student_id'].isin(left_out_student_ids)\n",
    "grouped = df[not_in_beginning & is_assessment_ixn & left_out].groupby('student_id')\n",
    "        \n",
    "student_cut_loc = grouped.timestep.max() - 1\n",
    "student_cut_loc.name = 'student_cut_loc'\n",
    "truncations = df.join(\n",
    "    student_cut_loc, on='student_id')['student_cut_loc'].fillna(\n",
    "    np.nan, inplace=False)\n",
    "\n",
    "left_in_students = [x for x in history.iter_students() if x not in left_out_student_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, t in enumerate(tset_sizes):\n",
    "    print '%d of %d' % (i, len(tset_sizes))\n",
    "    \n",
    "    tset = set(left_in_students[:int(t*len(left_in_students))])\n",
    "    left_in = df['student_id'].isin(tset)\n",
    "    \n",
    "    filtered_history = df[(left_in) | (\n",
    "            left_out & (df['timestep']<=truncations))]\n",
    "    \n",
    "    train_assessments = set(\n",
    "        filtered_history[filtered_history['module_type']==datatools.AssessmentInteraction.MODULETYPE]['module_id'].unique())\n",
    "    \n",
    "    split_history = history.split_interactions_by_type(\n",
    "            filtered_history=filtered_history)\n",
    "    \n",
    "    model = build_embedding(\n",
    "        embedding_kwargs,\n",
    "        estimator,\n",
    "        history,\n",
    "        filtered_history,\n",
    "        split_history=split_history)\n",
    "    \n",
    "    for student_id in left_out_student_ids:\n",
    "        group = grouped.get_group(student_id)\n",
    "        test_t = student_cut_loc.ix[student_id]+1\n",
    "        test_ixns = test_ixns[(test_ixns['timestep']==test_t) & (\n",
    "                test_ixns['module_id'].isin(train_assessments))]\n",
    "        if len(test_ixns)==0:\n",
    "            y_trues_for_tset_size_analysis[student_id].append([])\n",
    "            probas_preds_for_tset_size_analysis[student_id].append([])\n",
    "            continue\n",
    "        \n",
    "        y_trues_for_tset_size_analysis[student_id].append(list(test_ixns['outcome'].apply(\n",
    "            lambda outcome: 1 if outcome else -1)))\n",
    "        probas_preds_for_tset_size_analysis[student_id].append(list(test_ixns.apply(\n",
    "            model.assessment_pass_likelihood, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aucs = compute_auc(\n",
    "    y_trues_for_tset_size_analysis, \n",
    "    probas_preds_for_tset_size_analysis, \n",
    "    tset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Sensitivity to number of full student histories')\n",
    "plt.xlabel('Number of full student histories in training set')\n",
    "plt.ylabel('Area under ROC Curve')\n",
    "plt.plot(tset_sizes * len(left_in_students), aucs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
