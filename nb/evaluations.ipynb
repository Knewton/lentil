{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from lentil import datatools\n",
    "from lentil import evaluate\n",
    "from lentil import models\n",
    "from lentil import est\n",
    "from lentil import forget\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_path = os.path.join('data', 'assistments_2009_2010_history.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(history_path, 'rb') as f:\n",
    "    history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_1pl_irt_model(history, filtered_history, split_history=None):\n",
    "    model = models.OneParameterLogisticModel(filtered_history)\n",
    "    model.fit()\n",
    "    return model\n",
    "\n",
    "def build_2pl_irt_model(history, filtered_history, split_history=None):\n",
    "    model = models.TwoParameterLogisticModel(filtered_history)\n",
    "    model.fit()\n",
    "    return model\n",
    "\n",
    "def build_student_biased_coin_model(history, filtered_history, split_history=None):\n",
    "    model = models.StudentBiasedCoinModel(history, filtered_history)\n",
    "    model.fit()\n",
    "    return model\n",
    "\n",
    "def build_assessment_biased_coin_model(history, filtered_history, split_history=None):\n",
    "    model = models.AssessmentBiasedCoinModel(history, filtered_history)\n",
    "    model.fit()\n",
    "    return model\n",
    "\n",
    "def build_embedding(\n",
    "    embedding_kwargs,\n",
    "    estimator,\n",
    "    history,\n",
    "    filtered_history,\n",
    "    split_history=None):\n",
    "    \n",
    "    model = models.EmbeddingModel(history, **embedding_kwargs)\n",
    "    \n",
    "    estimator.filtered_history = filtered_history\n",
    "    if split_history is not None:\n",
    "        estimator.split_history = split_history\n",
    "    \n",
    "    model.fit(estimator)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def meta_build_embedding(\n",
    "    d=2,\n",
    "    using_lessons=True,\n",
    "    using_prereqs=True,\n",
    "    using_bias=True,\n",
    "    regularization_constant=1e-3,\n",
    "    using_scipy=True,\n",
    "    learning_update_variance_constant=0.5,\n",
    "    forgetting_penalty_term_constant=0.,\n",
    "    tv_luv_model=None,\n",
    "    forgetting_model=None,\n",
    "    using_graph_prior=None,\n",
    "    graph=None,\n",
    "    graph_regularization_constant=None):\n",
    "    \n",
    "    embedding_kwargs = {\n",
    "        'embedding_dimension' : d,\n",
    "        'using_lessons' : using_lessons,\n",
    "        'using_prereqs' : using_prereqs,\n",
    "        'using_bias' : using_bias,\n",
    "        'learning_update_variance_constant' : learning_update_variance_constant,\n",
    "        'tv_luv_model' : tv_luv_model,\n",
    "        'forgetting_model' : forgetting_model,\n",
    "        'forgetting_penalty_term_constant' : forgetting_penalty_term_constant,\n",
    "        'using_graph_prior' : using_graph_prior,\n",
    "        'graph' : graph,\n",
    "        'graph_regularization_constant' : graph_regularization_constant\n",
    "    }\n",
    "    \n",
    "    gradient_descent_kwargs = {\n",
    "        'using_adagrad' : False,\n",
    "        'eta' : 0.001,\n",
    "        'eps' : 0.1,\n",
    "        'rate' : 0.005,\n",
    "        'verify_gradient' : False,\n",
    "        'ftol' : 1e-3,\n",
    "        'max_iter' : 1000,\n",
    "        'num_checkpoints' : 100\n",
    "    }\n",
    "    \n",
    "    estimator = est.EmbeddingMAPEstimator(\n",
    "        regularization_constant=regularization_constant,\n",
    "        using_scipy=using_scipy,\n",
    "        gradient_descent_kwargs=gradient_descent_kwargs,\n",
    "        verify_gradient=False,\n",
    "        debug_mode_on=True,\n",
    "        ftol=1e-3)\n",
    "    \n",
    "    return (lambda *args, **kwargs: build_embedding(\n",
    "            embedding_kwargs,\n",
    "            estimator,\n",
    "            *args,\n",
    "            **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_builders = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# baselines\n",
    "model_builders = {\n",
    "    '0PL IRT (students)' : build_student_biased_coin_model,\n",
    "    '0PL IRT (assessments)' : build_assessment_biased_coin_model,\n",
    "    '1PL IRT' : build_1pl_irt_model,\n",
    "    '2PL IRT' : build_2pl_irt_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_update_variances = [1e-8, 1e-6, 1e-4, 1e-2, 0.5, 10., 100., 1000.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vary learning_update_variance\n",
    "for var in learning_update_variances:\n",
    "    model_builders['d=2, with bias, var=%f' % var] = meta_build_embedding(\n",
    "        d=2,\n",
    "        using_lessons=True,\n",
    "        using_prereqs=True,\n",
    "        using_bias=True,\n",
    "        learning_update_variance_constant=var)\n",
    "    \n",
    "# high learning_update_variance should simulate having no lessons\n",
    "model_builders['d=2, without lessons, with bias'] = meta_build_embedding(\n",
    "    d=2,\n",
    "    using_lessons=False,\n",
    "    using_prereqs=False,\n",
    "    using_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regularization_constants = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1., 10.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vary regularization_constant\n",
    "for const in regularization_constants:\n",
    "    model_builders['d=2, with bias, regularization_constant=%f' % const] = meta_build_embedding(\n",
    "        d=2,\n",
    "        using_lessons=True,\n",
    "        using_prereqs=True,\n",
    "        using_bias=True,\n",
    "        regularization_constant=const)\n",
    "    \n",
    "    # the effect of varying regularization \n",
    "    # is probably stronger when there are no bias terms\n",
    "    model_builders['d=2, without bias, regularization_constant=%f' % const] = meta_build_embedding(\n",
    "        d=2,\n",
    "        using_lessons=True,\n",
    "        using_prereqs=True,\n",
    "        using_bias=False,\n",
    "        regularization_constant=const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grid of regularization_constant and embedding_dimension values\n",
    "embedding_dimensions = [2, 5, 10, 20, 50]\n",
    "regularization_constants = [1e-8, 1e-6, 1e-4, 1e-2, 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in embedding_dimensions:\n",
    "    for const in regularization_constants:\n",
    "        model_builders['d=%d, with bias, regularization_constant=%f' % (d, const)] = meta_build_embedding(\n",
    "            d=d,\n",
    "            using_lessons=True,\n",
    "            using_prereqs=True,\n",
    "            using_bias=True,\n",
    "            regularization_constant=const,\n",
    "            using_scipy=(d<=10))\n",
    "        \n",
    "        # the effect of varying dimension and regularization \n",
    "        # is probably stronger when there are no bias terms\n",
    "        model_builders['d=%d, without bias, regularization_constant=%f' % (d, const)] = meta_build_embedding(\n",
    "            d=d,\n",
    "            using_lessons=True,\n",
    "            using_prereqs=True,\n",
    "            using_bias=False,\n",
    "            regularization_constant=const,\n",
    "            using_scipy=(d<=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lesion analysis\n",
    "\n",
    "# baselines\n",
    "model_builders = {\n",
    "    '0PL IRT (assessments)' : build_student_biased_coin_model,\n",
    "    '0PL IRT (students)' : build_assessment_biased_coin_model,\n",
    "    '1PL IRT' : build_1pl_irt_model,\n",
    "    '2PL IRT' : build_2pl_irt_model\n",
    "}\n",
    "\n",
    "# lesson|prereq|bias\n",
    "# Y|Y|Y\n",
    "model_builders['d=2, with prereqs and bias'] = meta_build_embedding(\n",
    "    d=2,\n",
    "    using_lessons=True,\n",
    "    using_prereqs=True,\n",
    "    using_bias=True)\n",
    "\n",
    "# Y|Y|N\n",
    "model_builders['d=2, with prereqs, without bias'] = meta_build_embedding(\n",
    "    d=2,\n",
    "    using_prereqs=True,\n",
    "    using_lessons=True,\n",
    "    using_bias=False)\n",
    "\n",
    "# Y|N|N\n",
    "model_builders['d=2, without prereqs and bias'] = meta_build_embedding(\n",
    "    d=2,\n",
    "    using_prereqs=False,\n",
    "    using_lessons=True,\n",
    "    using_bias=False)\n",
    "\n",
    "# Y|N|Y\n",
    "model_builders['d=2, without prereqs, with bias'] = meta_build_embedding(\n",
    "    d=2,\n",
    "    using_prereqs=False,\n",
    "    using_lessons=True,\n",
    "    using_bias=True)\n",
    "\n",
    "# N|N|N\n",
    "model_builders['d=2, without lessons and bias'] = meta_build_embedding(\n",
    "    d=2,\n",
    "    using_lessons=False,\n",
    "    using_prereqs=False,\n",
    "    using_bias=False)\n",
    "\n",
    "# N|N|Y\n",
    "model_builders['d=2, without lessons, with bias'] = meta_build_embedding(\n",
    "    d=2,\n",
    "    using_lessons=False,\n",
    "    using_prereqs=False,\n",
    "    using_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Number of models = %d\" % (len(model_builders))\n",
    "print '\\n'.join(model_builders.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = evaluate.cross_validated_auc(\n",
    "    model_builders,\n",
    "    history,\n",
    "    num_folds=10,\n",
    "    random_truncations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_path = os.path.join(\n",
    "    'results', 'random', 'assistments_2009_2010_results_lesion.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dump results to file\n",
    "with open(results_path, 'wb') as f:\n",
    "    pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load results from file, replacing current results\n",
    "with open(results_path, 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load results from file, merging with current results\n",
    "with open(results_path, 'rb') as f:\n",
    "    results = results.merge(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare models to baselines\n",
    "baselines = ['0PL IRT (students)', '0PL IRT (assessments)', '1PL IRT', '2PL IRT']\n",
    "for baseline in baselines:\n",
    "    for k in results.raw_results:\n",
    "        if k==baseline:\n",
    "            continue\n",
    "        print \"%s vs. %s:\" % (k, baseline)\n",
    "        print \"p-value = %f\" % (results.compare_validation_aucs(k, baseline))\n",
    "        print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compare with lessons to without lessons\n",
    "print \"without bias:\"\n",
    "print \"p-value = %f\" % (results.compare_validation_aucs(\n",
    "        'd=2, without lessons and bias', \n",
    "        'd=2, without prereqs and bias'))\n",
    "print ''\n",
    "print \"with bias:\"\n",
    "print \"p-value = %f\" % (results.compare_validation_aucs(\n",
    "        'd=2, without lessons, with bias', \n",
    "        'd=2, without prereqs, with bias'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare with prereqs to without prereqs\n",
    "print \"without bias:\"\n",
    "print \"p-value = %f\" % (results.compare_validation_aucs(\n",
    "        'd=2, with prereqs, without bias', \n",
    "        'd=2, without prereqs and bias'))\n",
    "print ''\n",
    "print \"with bias:\"\n",
    "print \"p-value = %f\" % (results.compare_validation_aucs(\n",
    "        'd=2, with prereqs and bias', \n",
    "        'd=2, without prereqs, with bias'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare with bias to without bias\n",
    "print \"with prereqs:\"\n",
    "print \"p-value = %f\" % (results.compare_validation_aucs(\n",
    "        'd=2, with prereqs, without bias', \n",
    "        'd=2, with prereqs and bias'))\n",
    "print ''\n",
    "print \"without prereqs:\"\n",
    "print \"p-value = %f\" % (results.compare_validation_aucs(\n",
    "        'd=2, without prereqs and bias',\n",
    "        'd=2, without prereqs, with bias'))\n",
    "print ''\n",
    "print \"without lessons:\"\n",
    "print \"p-value = %f\" % (results.compare_validation_aucs(\n",
    "        'd=2, without lessons and bias',\n",
    "        'd=2, without lessons, with bias'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Train\\tValidation\\tModel'\n",
    "names = ['0PL IRT (students)', '0PL IRT (assessments)', '1PL IRT', '2PL IRT', 'd=2, without lessons and bias',\n",
    "       'd=2, without lessons, with bias', 'd=2, without prereqs and bias', 'd=2, without prereqs, with bias',\n",
    "       'd=2, with prereqs, without bias', 'd=2, with prereqs and bias']\n",
    "for k in names:\n",
    "    try:\n",
    "        train_auc = results.training_auc_mean(k)\n",
    "        val_auc = results.validation_auc_mean(k)\n",
    "    except KeyError:\n",
    "        continue\n",
    "    print '%0.3f\\t%0.3f\\t\\t%s' % (train_auc, val_auc, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_d_vs_beta_grid(using_bias=True):\n",
    "    with_or_without_bias = 'with' if using_bias else 'without'\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.xlabel('Embedding dimension')\n",
    "    plt.ylabel('Area under ROC Curve')\n",
    "    plt.title('Validation Performance')\n",
    "\n",
    "    for const in regularization_constants:\n",
    "        ax.plot(\n",
    "            embedding_dimensions, \n",
    "            [results.validation_auc_mean('d=%d, %s bias, regularization_constant=%f' % (\n",
    "                        d, with_or_without_bias, const)) for d in embedding_dimensions], \n",
    "            '-s', label='beta=%f, %s bias' % (const, with_or_without_bias))\n",
    "\n",
    "    ax.plot(embedding_dimensions, [results.validation_auc_mean('0PL IRT (students)')] * len(embedding_dimensions), \n",
    "            '--', label='0PL IRT (students)')\n",
    "    ax.plot(embedding_dimensions, [results.validation_auc_mean('0PL IRT (assessments)')] * len(embedding_dimensions), \n",
    "            '--', label='0PL IRT (assessments)')\n",
    "    ax.plot(embedding_dimensions, [results.validation_auc_mean('1PL IRT')] * len(embedding_dimensions), \n",
    "            '--', label='1PL IRT')\n",
    "    ax.plot(embedding_dimensions, [results.validation_auc_mean('2PL IRT')] * len(embedding_dimensions), \n",
    "            '--', label='2PL IRT')\n",
    "\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.legend(bbox_to_anchor=(1., 1.))\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xticks(embedding_dimensions)\n",
    "    ax.set_xticklabels([str(x) for x in embedding_dimensions])\n",
    "    ax.get_xaxis().get_major_formatter().labelOnlyBase = False\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_d_vs_beta_grid(using_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_d_vs_beta_grid(using_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Regularization constant')\n",
    "plt.ylabel('Area under ROC Curve')\n",
    "plt.title('Validation Performance')\n",
    "\n",
    "plt.errorbar(\n",
    "    regularization_constants,\n",
    "    [results.validation_auc_mean('d=2, with bias, regularization_constant=%f' % const) for const in regularization_constants],\n",
    "    yerr=[1.96*results.validation_auc_stderr('d=2, with bias, regularization_constant=%f' % const) for const in regularization_constants],\n",
    "    label='d=2, with bias')\n",
    "\n",
    "plt.errorbar(\n",
    "    regularization_constants, \n",
    "    [results.validation_auc_mean('d=2, without bias, regularization_constant=%f' % const) for const in regularization_constants],\n",
    "    [1.96*results.validation_auc_stderr('d=2, without bias, regularization_constant=%f' % const) for const in regularization_constants],\n",
    "    label='d=2, without bias')\n",
    "\n",
    "plt.plot(regularization_constants, [results.validation_auc_mean('0PL IRT (students)')] * len(regularization_constants), \n",
    "        '--', label='0PL IRT (students)')\n",
    "plt.plot(regularization_constants, [results.validation_auc_mean('0PL IRT (assessments)')] * len(regularization_constants), \n",
    "        '--', label='0PL IRT (assessments)')\n",
    "plt.plot(regularization_constants, [results.validation_auc_mean('1PL IRT')] * len(regularization_constants), \n",
    "        '--', label='1PL IRT')\n",
    "plt.plot(regularization_constants, [results.validation_auc_mean('2PL IRT')] * len(regularization_constants), \n",
    "        '--', label='2PL IRT')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.legend(bbox_to_anchor=(1., 1.))\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.xlabel('Learning update variance')\n",
    "plt.ylabel('Area under ROC Curve')\n",
    "plt.title('Validation Performance')\n",
    "\n",
    "plt.errorbar(\n",
    "    learning_update_variances, \n",
    "    [results.validation_auc_mean('d=2, with bias, var=%f' % v) for v in learning_update_variances], \n",
    "    yerr=[1.96*results.validation_auc_stderr('d=2, with bias, var=%f' % v) for v in learning_update_variances],\n",
    "    label='d=2, with prereqs and bias')\n",
    "\n",
    "plt.plot(\n",
    "    learning_update_variances, \n",
    "    [results.validation_auc_mean('d=2, without lessons, with bias') for v in learning_update_variances], \n",
    "    label='d=2, without lessons, with bias')\n",
    "\n",
    "plt.plot(learning_update_variances, [results.validation_auc_mean('0PL IRT (students)')] * len(learning_update_variances), \n",
    "        '--', label='0PL IRT (students)')\n",
    "plt.plot(learning_update_variances, [results.validation_auc_mean('0PL IRT (assessments)')] * len(learning_update_variances), \n",
    "        '--', label='0PL IRT (assessments)')\n",
    "plt.plot(learning_update_variances, [results.validation_auc_mean('1PL IRT')] * len(learning_update_variances), \n",
    "        '--', label='1PL IRT')\n",
    "plt.plot(learning_update_variances, [results.validation_auc_mean('2PL IRT')] * len(learning_update_variances), \n",
    "        '--', label='2PL IRT')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.legend(bbox_to_anchor=(1., 1.))\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
