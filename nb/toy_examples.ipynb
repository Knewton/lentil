{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from lentil import datatools\n",
    "from lentil import datasynth\n",
    "from lentil import viztools\n",
    "from lentil import models\n",
    "from lentil import est\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. [One-dimensional Embedding](#One-dimensional-Embedding)\n",
    "2. [Assessment Grid](#Assessment-Grid)\n",
    "3. [Independent Assessments](#Independent-Assessments)\n",
    "4. [Independent Lessons](#Independent-Lessons)\n",
    "5. [Lesson Prerequisites](#Lesson-Prerequisites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-dimensional Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A one-dimensional embedding, where a single latent skill is enough to explain the data. The key observation here is that the model recovered positive skill gains for $L_1$, and ``correctly\" arranged students and assessments in the latent space. Initially, Carter fails both assessments, so his skill level is behind the requirements of both assessments. Lee passes $A_1$ but fails $A_2$, so his skill level is beyond the requirement for $A_1$, but behind the requirement for $A_2$. In an effort to improve their results, Lee and Carter complete lesson $L_1$ and retake both assessments. Now Carter passes $A_1$, but still fails $A_2$, so his new skill level is ahead of the requirements for $A_1$ but behind the requirements for $A_2$. Lee passes both assessments, so his new skill level exceeds the requirements for $A_1$ and $A_2$. This clear difference in results before completing lesson $L_1$ and after completing the lesson implies that $L_1$ had a positive effect on Lee and Carter's skill levels, hence the non-zero skill gain vector recovered for $L_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "def complete_assessment(student_id, assessment_id, outcome, timestep):\n",
    "    data.append(\n",
    "        {'module_id' : assessment_id,\n",
    "         'module_type' : datatools.AssessmentInteraction.MODULETYPE,\n",
    "         'outcome' : outcome,\n",
    "         'student_id' : student_id,\n",
    "         'timestep' : timestep})\n",
    "\n",
    "def complete_lesson(student_id, lesson_id, timestep):\n",
    "    data.append(\n",
    "        {'module_id' : lesson_id,\n",
    "         'module_type' : datatools.LessonInteraction.MODULETYPE,\n",
    "         'student_id' : student_id,\n",
    "         'timestep' : timestep})\n",
    "\n",
    "complete_assessment('Lee', 'A1', True, 1)\n",
    "complete_assessment('Carter', 'A1', False, 1)\n",
    "complete_assessment('Lee', 'A2', False, 1)\n",
    "complete_assessment('Carter', 'A2', False, 1)\n",
    "\n",
    "complete_lesson('Lee', 'L1', 2)\n",
    "complete_lesson('Carter', 'L1', 2)\n",
    "\n",
    "complete_assessment('Lee', 'A1', True, 2)\n",
    "complete_assessment('Carter', 'A1', True, 2)\n",
    "complete_assessment('Lee', 'A2', True, 2)\n",
    "complete_assessment('Carter', 'A2', False, 2)\n",
    "\n",
    "history = datatools.InteractionHistory(pd.DataFrame(data))\n",
    "history.squash_timesteps()\n",
    "print history.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_dimension = 2\n",
    "\n",
    "model = models.EmbeddingModel(\n",
    "    history, \n",
    "    embedding_dimension,\n",
    "    using_lessons=True,\n",
    "    using_prereqs=False,\n",
    "    using_bias=False,\n",
    "    learning_update_variance_constant=0.5)\n",
    "\n",
    "gradient_descent_kwargs = {\n",
    "    'using_adagrad' : False,\n",
    "    'rate' : 0.1,\n",
    "    'debug_mode_on' : False\n",
    "}\n",
    "\n",
    "estimator = est.EmbeddingMAPEstimator(\n",
    "    regularization_constant=0.01,\n",
    "    gradient_descent_kwargs=gradient_descent_kwargs,\n",
    "    using_scipy=True,\n",
    "    debug_mode_on=True,\n",
    "    verify_gradient=True)\n",
    "\n",
    "model.fit(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_plot_embedding(model, timestep):\n",
    "    \"\"\"\n",
    "    Convenience function for calling plot_embedding with custom parameters\n",
    "    without re-typing all of them\n",
    "    \"\"\"\n",
    "    viztools.plot_embedding(\n",
    "        model, \n",
    "        timestep,\n",
    "        title=\"Latent Skill Space at Timestep \" + str(timestep if timestep!=-1 else model.history.duration()-1),\n",
    "        show_student_ids=True,\n",
    "        show_assessment_ids=True,\n",
    "        show_lesson_ids=True,\n",
    "        id_padding_x=0.,\n",
    "        id_padding_y=0.1,\n",
    "        show_legend=False,\n",
    "        force_invariant_axis_limits=True,\n",
    "        axis_limit_padding=0.4,\n",
    "        x_axis_limits=None,\n",
    "        y_axis_limits=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(1, model.history.duration()):\n",
    "    my_plot_embedding(model, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessment Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A two-dimensional grid of assessments and a single student\n",
    "        somewhere in the middle of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dimension = 2\n",
    "num_assessments = 100\n",
    "num_attempts = 50\n",
    "\n",
    "id_of_assessment_idx = lambda idx: 'A' + str(idx + 1)\n",
    "\n",
    "def sample_students():\n",
    "    \"\"\"\n",
    "    Fixed at (0.5, 0.5)\n",
    "    \"\"\"\n",
    "    duration = 2\n",
    "    S = np.zeros((1, embedding_dimension, duration))\n",
    "    S.fill(0.5)\n",
    "    return S\n",
    "    \n",
    "def sample_assessments():\n",
    "    \"\"\"\n",
    "    Uniform grid from (0,0) to (1,1),\n",
    "    excluding (1,1)\n",
    "    \"\"\"\n",
    "    A = np.zeros((num_assessments,\n",
    "                  embedding_dimension))\n",
    "    grid_length = int(math.sqrt(num_assessments))\n",
    "    for i in xrange(grid_length):\n",
    "        for j in xrange(grid_length):\n",
    "            A[i*grid_length+j, 0] = 1 / grid_length * i\n",
    "            A[i*grid_length+j, 1] = 1 / grid_length * j\n",
    "    return A\n",
    "    \n",
    "def sample_lessons():\n",
    "    \"\"\"\n",
    "    No lessons\n",
    "    \"\"\"\n",
    "    return None\n",
    "\n",
    "def sample_prereqs():\n",
    "    \"\"\"\n",
    "    No lesson prereqs\n",
    "    \"\"\"\n",
    "    return None\n",
    "\n",
    "def sample_interactions(model):\n",
    "    \"\"\"\n",
    "    student works on assessment 1 [num_attempts] times\n",
    "    student works on assessment 2 [num_attempts] times\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    student works on assessment [num_assessments] [num_attempts] times\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    student_id = 'Carl'\n",
    "    student = model.student_embeddings[0, :, 1]\n",
    "    student_bias = 0\n",
    "    for i in xrange(num_assessments):\n",
    "        assessment_id = id_of_assessment_idx(i)\n",
    "        assessment = model.assessment_embeddings[i, :]\n",
    "        assessment_bias = 0\n",
    "        pass_likelihood = math.exp(model.assessment_outcome_log_likelihood_helper(student, assessment, student_bias, assessment_bias, 1))\n",
    "        for j in xrange(num_attempts):\n",
    "            timestep = 1+i*num_attempts + j\n",
    "            outcome = random.random() < pass_likelihood\n",
    "\n",
    "            data.append(\n",
    "                {'module_id' : assessment_id, \n",
    "                 'module_type' : datatools.AssessmentInteraction.MODULETYPE, \n",
    "                 'outcome' : outcome, \n",
    "                 'student_id' : student_id, \n",
    "                 'timestep' : timestep})\n",
    "        \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_kwargs = {\n",
    "    'embedding_dimension' : embedding_dimension,\n",
    "    'using_lessons' : False,\n",
    "    'using_prereqs' : False,\n",
    "    'using_bias' : False,\n",
    "    'learning_update_variance_constant' : 0.5\n",
    "}\n",
    "\n",
    "model = datasynth.sample_synthetic_model_and_history(\n",
    "    sample_students, \n",
    "    sample_assessments,\n",
    "    sample_interactions,\n",
    "    sample_lessons=sample_lessons,\n",
    "    sample_prereqs=sample_prereqs,\n",
    "    embedding_kwargs=embedding_kwargs)\n",
    "\n",
    "num_students = model.student_embeddings.shape[0]\n",
    "num_assessments = model.assessment_embeddings.shape[0]\n",
    "model.student_biases = np.zeros(num_students)\n",
    "model.assessment_biases = np.zeros(num_assessments)\n",
    "\n",
    "assessment_idx_map = {id_of_assessment_idx(i):i for i in xrange(num_assessments)}\n",
    "model.history.compute_idx_maps(assessment_idx=assessment_idx_map)\n",
    "\n",
    "model.history.squash_timesteps()\n",
    "\n",
    "true_model = copy.deepcopy(model)\n",
    "print model.history.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradient_descent_kwargs = {\n",
    "    'using_adagrad' : False,\n",
    "    'rate' : 0.0005,\n",
    "    'ftol' : 1e-5,\n",
    "    'debug_mode_on' : True\n",
    "}\n",
    "\n",
    "estimator = est.EmbeddingMAPEstimator(\n",
    "    regularization_constant=0.01,\n",
    "    gradient_descent_kwargs=gradient_descent_kwargs,\n",
    "    using_scipy=True,\n",
    "    ftol=1e-3,\n",
    "    debug_mode_on=True,\n",
    "    verify_gradient=True)\n",
    "\n",
    "model.fit(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_plot_embedding(model, timestep, title=None):\n",
    "    \"\"\"\n",
    "    Convenience function for calling plot_embedding with custom parameters\n",
    "    without re-typing all of them\n",
    "    \"\"\"\n",
    "    viztools.plot_embedding(\n",
    "        model, \n",
    "        timestep,\n",
    "        title=title if title is not None else (\"Latent Skill Space at Timestep \" + str(timestep if timestep!=-1 else model.history.duration()-1)),\n",
    "        show_student_ids=True,\n",
    "        show_assessment_ids=False,\n",
    "        show_lesson_ids=False,\n",
    "        show_lessons=False,\n",
    "        show_prereqs=False,\n",
    "        id_padding_x=0.,\n",
    "        id_padding_y=0.,\n",
    "        show_legend=False,\n",
    "        force_invariant_axis_limits=True,\n",
    "        axis_limit_padding=0.1,\n",
    "        show_pass_rates=True,\n",
    "        size=60,\n",
    "        x_axis_limits=None,\n",
    "        y_axis_limits=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_plot_embedding(true_model, -1, title='True Embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_plot_embedding(model, -1, title='Estimated Embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independent Assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A two-dimensional embedding, where an intransitivity in assessment results requires more than one latent skill to explain. The key observation here is that the assessments are embedded on two different axes, meaning they require two completely independent skills. This makes sense, since student results on $A_1$ are uncorrelated with results on $A_2$. Fogell fails both assessments, so his skill levels are behind the requirements for $A_1$ and $A_2$. McLovin passes both assessments, so his skill levels are beyond the requirements for $A_1$ and $A_2$. Evan and Seth are each able to pass one assessment but not the other. Since the assessments have independent requirements, this implies that Evan and Seth have independent skill sets (i.e. Evan has enough of skill 2 to pass $A_2$ but not enough of skill 1 to pass $A_1$, and Seth has enough of skill 1 to pass $A_1$ but not enough of skill 2 to pass $A_2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "def complete_assessment(module_id, student_id, outcome, timestep):\n",
    "    data.append(\n",
    "        {'module_id' : module_id, \n",
    "         'module_type' : datatools.AssessmentInteraction.MODULETYPE, \n",
    "         'outcome' : outcome, \n",
    "         'student_id' : student_id, \n",
    "         'timestep' : timestep})\n",
    "\n",
    "complete_assessment('A1', 'McLovin', True, 1)\n",
    "complete_assessment('A2', 'McLovin', True, 2)\n",
    "\n",
    "complete_assessment('A1', 'Fogell', False, 1)\n",
    "complete_assessment('A2', 'Fogell', False, 2)\n",
    "\n",
    "complete_assessment('A1', 'Seth', True, 1)\n",
    "complete_assessment('A2', 'Seth', False, 2)\n",
    "\n",
    "complete_assessment('A1', 'Evan', False, 1)\n",
    "complete_assessment('A2', 'Evan', True, 3)\n",
    "\n",
    "history = datatools.InteractionHistory(pd.DataFrame(data))\n",
    "history.squash_timesteps()\n",
    "print history.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_dimension = 2\n",
    "\n",
    "model = models.EmbeddingModel(\n",
    "    history, \n",
    "    embedding_dimension,\n",
    "    using_prereqs=False,\n",
    "    using_lessons=False,\n",
    "    using_bias=False,\n",
    "    learning_update_variance_constant=0.5)\n",
    "\n",
    "gradient_descent_kwargs = {\n",
    "    'using_adagrad' : False,\n",
    "    'rate' : 0.1,\n",
    "    'debug_mode_on' : True\n",
    "}\n",
    "\n",
    "estimator = est.EmbeddingMAPEstimator(\n",
    "    regularization_constant=1e-3,\n",
    "    gradient_descent_kwargs=gradient_descent_kwargs,\n",
    "    using_scipy=True,\n",
    "    debug_mode_on=True,\n",
    "    verify_gradient=True)\n",
    "\n",
    "model.fit(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_plot_embedding(model, timestep):\n",
    "    \"\"\"\n",
    "    Convenience function for calling plot_embedding with custom parameters\n",
    "    without re-typing all of them\n",
    "    \"\"\"\n",
    "    viztools.plot_embedding(\n",
    "        model, \n",
    "        timestep,\n",
    "        title=\"Latent Skill Space at Timestep \" + str(timestep if timestep!=-1 else model.history.duration()-1),\n",
    "        show_student_ids=True,\n",
    "        show_assessment_ids=True,\n",
    "        show_lesson_ids=False,\n",
    "        id_padding_x=0.,\n",
    "        id_padding_y=0.05,\n",
    "        show_legend=False,\n",
    "        force_invariant_axis_limits=True,\n",
    "        axis_limit_padding=0.1,\n",
    "        show_pass_rates=False,\n",
    "        size=20,\n",
    "        x_axis_limits=None,\n",
    "        y_axis_limits=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_plot_embedding(model, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independent Lessons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replicate the setting in [Independent Assessments](#Independent-Assessments), then add two new students Slater and Michaels, and two new lesson modules $L_1$ and $L_2$. Slater is initially identical to Evan, while Michaels is initially identical to Seth. Slater reads lesson $L_1$, then passes assessments $A_1$ and $A_2$. Michaels reads lesson $L_2$, then passes assessments $A_1$ and $A_2$. The key observation here is that the skill gain vectors recovered for the two lesson modules are orthogonal, meaning they help students satisfy completely independent skill requirements. This makes sense, since initially Slater was lacking in Skill 1 while Michaels was lacking in Skill 2, but after completing their lessons they passed their assessments, showing that they gained from their respective lessons what they were lacking initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "def complete_lesson(lesson_id, student_id, timestep):\n",
    "    data.append(\n",
    "        {'module_id' : lesson_id, \n",
    "         'module_type' : datatools.LessonInteraction.MODULETYPE, \n",
    "         'outcome' : None, \n",
    "         'student_id' : student_id, \n",
    "         'timestep' : timestep})\n",
    "\n",
    "def complete_assessment(assessment_id, student_id, outcome, start_time):\n",
    "    data.append(\n",
    "        {'module_id' : assessment_id, \n",
    "         'module_type' : datatools.AssessmentInteraction.MODULETYPE, \n",
    "         'outcome' : outcome, \n",
    "         'student_id' : student_id, \n",
    "         'timestep' : start_time})\n",
    "\n",
    "complete_assessment('A1', 'McLovin', True, 1)\n",
    "complete_assessment('A2', 'McLovin', True, 2)\n",
    "\n",
    "complete_assessment('A1', 'Fogell', False, 1)\n",
    "complete_assessment('A2', 'Fogell', False, 2)\n",
    "\n",
    "complete_assessment('A1', 'Seth', True, 1)\n",
    "complete_assessment('A2', 'Seth', False, 2)\n",
    "\n",
    "complete_assessment('A1', 'Evan', False, 1)\n",
    "complete_assessment('A2', 'Evan', True, 3)\n",
    "\n",
    "complete_assessment('A1', 'Michaels', True, 1)\n",
    "complete_assessment('A2', 'Michaels', False, 1)\n",
    "\n",
    "complete_assessment('A1', 'Slater', False, 1)\n",
    "complete_assessment('A2', 'Slater', True, 1)\n",
    "\n",
    "complete_lesson('L1', 'Michaels', 4)\n",
    "complete_lesson('L2', 'Slater', 4)\n",
    "\n",
    "complete_assessment('A1', 'Michaels', True, 5)\n",
    "complete_assessment('A2', 'Michaels', True, 6)\n",
    "\n",
    "complete_assessment('A1', 'Slater', True, 5)\n",
    "complete_assessment('A2', 'Slater', True, 6)\n",
    "\n",
    "history = datatools.InteractionHistory(pd.DataFrame(data))\n",
    "history.squash_timesteps()\n",
    "print history.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_dimension = 2\n",
    "\n",
    "model = models.EmbeddingModel(\n",
    "    history, \n",
    "    embedding_dimension,\n",
    "    using_prereqs=False,\n",
    "    using_lessons=True,\n",
    "    using_bias=False,\n",
    "    learning_update_variance_constant=0.5) \n",
    "\n",
    "gradient_descent_kwargs = {\n",
    "    'using_adagrad' : False,\n",
    "    'rate' : 0.1,\n",
    "    'debug_mode_on' : True\n",
    "}\n",
    "\n",
    "estimator = est.EmbeddingMAPEstimator(\n",
    "    regularization_constant=1e-3,\n",
    "    gradient_descent_kwargs=gradient_descent_kwargs,\n",
    "    using_scipy=True,\n",
    "    debug_mode_on=True,\n",
    "    verify_gradient=True)\n",
    "\n",
    "model.fit(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_plot_embedding(model, timestep):\n",
    "    \"\"\"\n",
    "    Convenience function for calling plot_embedding with custom parameters\n",
    "    without re-typing all of them\n",
    "    \"\"\"\n",
    "    viztools.plot_embedding(\n",
    "        model, \n",
    "        timestep,\n",
    "        title=\"Latent Skill Space at Timestep \" + str(timestep if timestep!=-1 else model.history.duration()-1),\n",
    "        show_student_ids=True,\n",
    "        show_assessment_ids=True,\n",
    "        show_lesson_ids=True,\n",
    "        show_lessons=True,\n",
    "        id_padding_x=0.,\n",
    "        id_padding_y=0.05,\n",
    "        show_legend=False,\n",
    "        force_invariant_axis_limits=True,\n",
    "        axis_limit_padding=0.1,\n",
    "        show_pass_rates=False,\n",
    "        size=20,\n",
    "        x_axis_limits=None,\n",
    "        y_axis_limits=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(1, model.history.duration()):\n",
    "    my_plot_embedding(model, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lesson Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replicate the setting in [Independent Assessments](#Independent-Assessments), then add a new assessment module $A_3$ and a new lesson module $L_1$. All students initially fail assessment $A_3$, then read lesson $L_1$, after which McLovin passes $A_3$ while everyone else still fails $A_3$. The key observation here is that McLovin is the only student who initially satisfies the prerequisites for $L_1$, so he is the only student who realizes significant gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "def complete_assessment(assessment_id, student_id, outcome, timestep):\n",
    "    data.append(\n",
    "        {'module_id' : assessment_id, \n",
    "         'module_type' : datatools.AssessmentInteraction.MODULETYPE, \n",
    "         'outcome' : outcome, \n",
    "         'student_id' : student_id, \n",
    "         'timestep' : timestep})\n",
    "\n",
    "def complete_lesson(lesson_id, student_id, timestep):\n",
    "    data.append(\n",
    "        {'module_id' : lesson_id, \n",
    "         'module_type' : datatools.LessonInteraction.MODULETYPE, \n",
    "         'outcome' : None, \n",
    "         'student_id' : student_id, \n",
    "         'timestep' : timestep})\n",
    "\n",
    "complete_assessment('A1', 'McLovin', True, 1)\n",
    "complete_assessment('A2', 'McLovin', True, 2)\n",
    "\n",
    "complete_assessment('A1', 'Fogell', False, 1)\n",
    "complete_assessment('A2', 'Fogell', False, 2)\n",
    "\n",
    "complete_assessment('A1', 'Seth', True, 1)\n",
    "complete_assessment('A2', 'Seth', False, 2)\n",
    "\n",
    "complete_assessment('A1', 'Evan', False, 1)\n",
    "complete_assessment('A2', 'Evan', True, 3)\n",
    "\n",
    "complete_assessment('A3', 'McLovin', False, 4)\n",
    "complete_assessment('A3', 'Fogell', False, 4)\n",
    "complete_assessment('A3', 'Seth', False, 4)\n",
    "complete_assessment('A3', 'Evan', False, 4)\n",
    "\n",
    "complete_lesson('L1', 'McLovin', 5)\n",
    "complete_lesson('L1', 'Fogell', 5)\n",
    "complete_lesson('L1', 'Seth', 5)\n",
    "complete_lesson('L1', 'Evan', 5)\n",
    "\n",
    "complete_assessment('A3', 'McLovin', True, 6)\n",
    "\n",
    "complete_assessment('A3', 'Fogell', False, 6)\n",
    "complete_assessment('A3', 'Seth', False, 6)\n",
    "complete_assessment('A3', 'Evan', False, 6)\n",
    "\n",
    "history = datatools.InteractionHistory(pd.DataFrame(data))\n",
    "history.squash_timesteps()\n",
    "print history.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_dimension = 2\n",
    "\n",
    "model = models.EmbeddingModel(\n",
    "    history,\n",
    "    embedding_dimension,\n",
    "    using_lessons=True,\n",
    "    using_prereqs=True,\n",
    "    using_bias=False,\n",
    "    learning_update_variance_constant=0.5)  \n",
    "\n",
    "gradient_descent_kwargs = {\n",
    "    'using_adagrad' : False,\n",
    "    'rate' : 0.01,\n",
    "    'ftol' : 1e-4,\n",
    "    'debug_mode_on' : True\n",
    "}\n",
    "\n",
    "estimator = est.EmbeddingMAPEstimator(\n",
    "    regularization_constant=1e-3,\n",
    "    gradient_descent_kwargs=gradient_descent_kwargs,\n",
    "    using_scipy=True,\n",
    "    debug_mode_on=True,\n",
    "    verify_gradient=True)\n",
    "\n",
    "model.fit(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_plot_embedding(model, timestep):\n",
    "    \"\"\"\n",
    "    Convenience function for calling plot_embedding with custom parameters\n",
    "    without re-typing all of them\n",
    "    \"\"\"\n",
    "    viztools.plot_embedding(\n",
    "        model, \n",
    "        timestep,\n",
    "        title=\"Latent Skill Space at Timestep \" + str(timestep),\n",
    "        show_student_ids=True,\n",
    "        show_assessment_ids=True,\n",
    "        show_lesson_ids=True,\n",
    "        id_padding_x=-0.01,\n",
    "        id_padding_y=0.01,\n",
    "        show_legend=False,\n",
    "        force_invariant_axis_limits=True,\n",
    "        axis_limit_padding=0.4,\n",
    "        x_axis_limits=None,\n",
    "        y_axis_limits=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(1, model.history.duration()):\n",
    "    my_plot_embedding(model, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
